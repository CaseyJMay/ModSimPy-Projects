{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Jupyter so figures appear in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Configure Jupyter to display the assigned value after an assignment\n",
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'\n",
    "\n",
    "# import functions from the modsim library\n",
    "from modsim import *\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLAN:\n",
    "Use historical data to fine-tune parameters for baseline model (with both WWI and Spanish Flu)\n",
    "Use Modified data (Linear fit for life expectancy and birth rate, removing data points from 1910-1920) to generate a control model without the war or flu\n",
    "Isolate effects of WWI and Spanish flu by increasing death rates / decreasing birth rates within different age groups for each respective event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1900.0,\n",
       " 1901.0,\n",
       " 1902.0,\n",
       " 1903.0,\n",
       " 1904.0,\n",
       " 1905.0,\n",
       " 1906.0,\n",
       " 1907.0,\n",
       " 1908.0,\n",
       " 1909.0,\n",
       " 1910.0,\n",
       " 1911.0,\n",
       " 1912.0,\n",
       " 1913.0,\n",
       " 1914.0,\n",
       " 1915.0,\n",
       " 1916.0,\n",
       " 1917.0,\n",
       " 1918.0,\n",
       " 1919.0,\n",
       " 1920.0,\n",
       " 1921.0,\n",
       " 1922.0,\n",
       " 1923.0,\n",
       " 1924.0,\n",
       " 1925.0,\n",
       " 1926.0,\n",
       " 1927.0,\n",
       " 1928.0,\n",
       " 1929.0,\n",
       " 1930.0,\n",
       " 1931.0,\n",
       " 1932.0,\n",
       " 1933.0,\n",
       " 1934.0,\n",
       " 1935.0,\n",
       " 1936.0,\n",
       " 1937.0,\n",
       " 1938.0,\n",
       " 1939.0,\n",
       " 1940.0,\n",
       " 1941.0,\n",
       " 1942.0,\n",
       " 1943.0,\n",
       " 1944.0,\n",
       " 1945.0,\n",
       " 1946.0,\n",
       " 1947.0,\n",
       " 1948.0,\n",
       " 1949.0]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#population of italy (millions) 1900 to 1949 \n",
    "#http://www.populstat.info/Europe/italyc.htm\n",
    "T_START = 1900\n",
    "T_END = 1949\n",
    "pop_data = [32.4750, 32.0454, 32.5956, 32.9612, 33.2183, \n",
    "       33.4761, 33.7332, 33.6407, 33.9098, 34.2698,\n",
    "       34.5652, 35.1318, 35.2390, 35.5978, 36.1201,\n",
    "       36.5464, 36.6024, 36.5829, 36.3700, 37.8370,\n",
    "       38.7560, 38.7900, 39.1360, 39.4010, 39.6930,\n",
    "       39.5846, 39.6810, 40.0540, 40.4450, 40.7030,\n",
    "       41.1767, 41.5800, 41.9300, 41.8060, 42.2170,\n",
    "       42.4446, 43.5780, 43.8430, 44.3940, 43.7870,\n",
    "       44.8300, 45.3870, 48.8300, 44.9400, 45.4150, \n",
    "       45.3800, 45.7200, 46.3810, 46.7330, 46.1040]\n",
    "\n",
    "#life expectancy data\n",
    "#https://en.wikipedia.org/wiki/Demographics_of_Italy\n",
    "lifexp_data = [43.5, 43.0, 43.1, 44.4, 43.9, 45.2, 45.4, 43.1, 44.6, 46.7,\n",
    "          44.7, 48.9, 48.4, 49.9, 42.5, 39.6, 38.1, 25.8, 42.3, 45.5,\n",
    "          49.2, 50.0, 51.4, 51.5, 51.3, 50.9, 52.5, 52.6, 52.3, 55.2,\n",
    "          54.8, 54.7, 56.3, 56.8, 56.2, 56.7, 55.5, 56.1, 57.6, 57.0,\n",
    "          54.7, 52.5, 49.4, 52.4, 54.9, 59.0, 61.2, 63.4, 64.1, 65.8]\n",
    "\n",
    "#birthrate data\n",
    "birth_data = [33.0, 32.5, 33.3, 31.6, 32.7, 32.4, 31.8, 31.3, 33.3, 32.4,\n",
    "              32.9, 31.2, 32.2, 31.8, 31.2, 30.6, 24.2, 19.6, 18.2, 21.6, \n",
    "              32.2, 30.7, 30.8, 29.9, 28.9, 28.2, 27.7, 27.4, 26.6, 25.6,\n",
    "              26.7, 24.8, 23.8, 23.8, 23.5, 23.4, 22.4, 22.9, 23.8, 23.6, \n",
    "              23.5, 20.9, 20.5, 19.8, 18.3, 18.2, 23.0, 22.2, 21.8, 20.1]\n",
    "\n",
    "y = [1900., 1901., 1902., 1903., 1904., 1905., 1906., 1907., 1908.,\n",
    "     1909., 1910., 1911., 1912., 1913., 1914., 1915., 1916., 1917.,\n",
    "     1918., 1919., 1920., 1921., 1922., 1923., 1924., 1925., 1926.,\n",
    "     1927., 1928., 1929., 1930., 1931., 1932., 1933., 1934., 1935.,\n",
    "     1936., 1937., 1938., 1939., 1940., 1941., 1942., 1943., 1944.,\n",
    "     1945., 1946., 1947., 1948., 1949.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x236fbcabc18>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot italy pop data\n",
    "plot(y,pop_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x236fbbb8550>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot italy life expectancy data\n",
    "plot(y,birth_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x236fbc147b8>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot italy birthrate data\n",
    "plot(y,lifexp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life expectancy =  0.4121520257938937  * year -  740.7973427424291\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to get a baseline life expectancy (no disease or war)\n",
    "#eliminate data points that exhibit a drop\n",
    "\n",
    "modlifexp = [43.5, 43.0, 43.1, 44.4, 43.9, 45.2, 45.4, 43.1, 44.6, 46.7,\n",
    "          44.7, 48.9, 48.4, 49.9, \n",
    "          49.2, 50.0, 51.4, 51.5, 51.3, 50.9, 52.5, 52.6, 52.3, 55.2,\n",
    "          54.8, 54.7, 56.3, 56.8, 56.2, 56.7, 55.5, 56.1, 57.6, 57.0,\n",
    "                                        59.0, 61.2, 63.4, 64.1, 65.8]\n",
    "\n",
    "modt_lifexp = [1900., 1901., 1902., 1903., 1904., 1905., 1906., 1907., 1908.,\n",
    "     1909., 1910., 1911., 1912., 1913., 1920., 1921., 1922., 1923., 1924., 1925., 1926.,\n",
    "     1927., 1928., 1929., 1930., 1931., 1932., 1933., 1934., 1935.,\n",
    "     1936., 1937., 1938., 1939., 1945., 1946., 1947., 1948., 1949.]\n",
    "\n",
    "#assume linear increase of life expectancy\n",
    "m1,b1 = np.polyfit(modt_lifexp, modlifexp, 1) \n",
    "\n",
    "plot(modt_lifexp,modlifexp, 'yo')\n",
    "t = linspace(T_START, T_END, T_END - T_START + 1)\n",
    "plot(t, m1*t+b1, '--k') \n",
    "print('Life expectancy = ',m1,' * year - ', -b1)\n",
    "\n",
    "#From linear life expectancy...\n",
    "#Dramatically drop life expectancy/birthrate in different age groups over a short period of time\n",
    "#To Isolate effects of disesase/war"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birthrate =  -0.00030174404652519716  * year -  -0.6080990867915439\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to get a baseline birthrate (no disease or war)\n",
    "#eliminate data points that exhibit a drop\n",
    "\n",
    "modbirthdata = [33.0, 32.5, 33.3, 31.6, 32.7, 32.4, 31.8, 31.3, 33.3, 32.4,\n",
    "              32.9, 31.2, 32.2, 31.8, 31.2, 30.6,  \n",
    "              32.2, 30.7, 30.8, 29.9, 28.9, 28.2, 27.7, 27.4, 26.6, 25.6,\n",
    "              26.7, 24.8, 23.8, 23.8, 23.5, 23.4, 22.4, 22.9, 23.8, 23.6, \n",
    "              23.5, 20.9, 20.5, 19.8, 18.3, 18.2, 23.0, 22.2, 21.8, 20.1]\n",
    "\n",
    "modbirth = [b/1000 for b in modbirthdata]\n",
    "\n",
    "modt_birth = [1900., 1901., 1902., 1903., 1904., 1905., 1906., 1907., 1908.,\n",
    "     1909., 1910., 1911., 1912., 1913., \n",
    "     1918., 1919., 1920., 1921., 1922., 1923., 1924., 1925., 1926.,\n",
    "     1927., 1928., 1929., 1930., 1931., 1932., 1933., 1934., 1935.,\n",
    "     1936., 1937., 1938., 1939., 1940., 1941., 1942., 1943., 1944.,\n",
    "     1945., 1946., 1947., 1948., 1949.]\n",
    "\n",
    "#assume linear decrease of birthrate\n",
    "m2,b2 = np.polyfit(modt_birth, modbirth, 1) \n",
    "\n",
    "plot(modt_birth,modbirth, 'yo')\n",
    "plot(t, m2*t+b2, '--k') \n",
    "print('Birthrate = ',m2,' * year - ', -b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#young 0-15\n",
    "#mid 16-39\n",
    "#old 40-life expectancy\n",
    "\n",
    "#Mature rate young to mid\n",
    "MATURE1 = 1/16\n",
    "#Mature rate mid to old\n",
    "MATURE2 = 1/24\n",
    "#death = 1/(lifexp[t]-40)\n",
    "\n",
    "#ASSUMPTION: Each Age is equally likely\n",
    "\n",
    "p_0 = pop[0]\n",
    "yng_0 = p_0 * 1/(MATURE1*42)\n",
    "mid_0 = p_0 * 1/(MATURE2*42)\n",
    "old_0 = p_0 * 2/42\n",
    "\n",
    "\n",
    "lifexp = TimeSeries()\n",
    "for t in linrange(T_START, T_END):\n",
    "        lifexp[t] = m1*(t) + b1\n",
    "        \n",
    "birthrate = TimeSeries()\n",
    "for t in linrange(T_START, T_END):\n",
    "        birthrate[t] = m2*(t) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TIMESTEP\n",
    "\n",
    "#delta young = young pop*MATURE1\n",
    "#delta mid = mid pop*MATURE2\n",
    "#delta old = old pop * death[t]\n",
    "#Young population increases by pop*birthrate[t]\n",
    "#delta young moves from young to mid\n",
    "#delta mid moves from mid to old\n",
    "#old decreases by delta old\n",
    "#pop = young plus old plus mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TimeSeries in module modsim object:\n",
      "\n",
      "class TimeSeries(ModSimSeries)\n",
      " |  Represents a mapping from times to values.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TimeSeries\n",
      " |      ModSimSeries\n",
      " |      pandas.core.series.Series\n",
      " |      pandas.core.base.IndexOpsMixin\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.base.StringMixin\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods inherited from ModSimSeries:\n",
      " |  \n",
      " |  __copy__(self, deep=True)\n",
      " |  \n",
      " |  __init__(self, *args, **kwargs)\n",
      " |      Initialize a Series.\n",
      " |      \n",
      " |      Note: this cleans up a weird Series behavior, which is\n",
      " |      that Series() and Series([]) yield different results.\n",
      " |      See: https://github.com/pandas-dev/pandas/issues/16737\n",
      " |  \n",
      " |  copy = __copy__(self, deep=True)\n",
      " |  \n",
      " |  set(self, **kwargs)\n",
      " |      Uses keyword arguments to update the Series in place.\n",
      " |      \n",
      " |      Example: series.set(a=1, b=2)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from ModSimSeries:\n",
      " |  \n",
      " |  T\n",
      " |      Intercept the Series accessor object so we can use `T`\n",
      " |      as a row label and access it using dot notation.\n",
      " |      \n",
      " |      https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.T.html\n",
      " |  \n",
      " |  dt\n",
      " |      Intercept the Series accessor object so we can use `dt`\n",
      " |      as a row label and access it using dot notation.\n",
      " |      \n",
      " |      https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.dt.html\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.series.Series:\n",
      " |  \n",
      " |  __add__ = wrapper(left, right)\n",
      " |  \n",
      " |  __and__ = wrapper(self, other)\n",
      " |  \n",
      " |  __array__(self, result=None)\n",
      " |      the array interface, return my values\n",
      " |  \n",
      " |  __array_prepare__(self, result, context=None)\n",
      " |      Gets called prior to a ufunc\n",
      " |  \n",
      " |  __array_wrap__(self, result, context=None)\n",
      " |      Gets called after a ufunc\n",
      " |  \n",
      " |  __div__ = wrapper(left, right)\n",
      " |  \n",
      " |  __divmod__ = wrapper(left, right)\n",
      " |  \n",
      " |  __eq__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __float__ = wrapper(self)\n",
      " |  \n",
      " |  __floordiv__ = wrapper(left, right)\n",
      " |  \n",
      " |  __ge__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __gt__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __iadd__ = f(self, other)\n",
      " |  \n",
      " |  __iand__ = f(self, other)\n",
      " |  \n",
      " |  __ifloordiv__ = f(self, other)\n",
      " |  \n",
      " |  __imod__ = f(self, other)\n",
      " |  \n",
      " |  __imul__ = f(self, other)\n",
      " |  \n",
      " |  __int__ = wrapper(self)\n",
      " |  \n",
      " |  __ior__ = f(self, other)\n",
      " |  \n",
      " |  __ipow__ = f(self, other)\n",
      " |  \n",
      " |  __isub__ = f(self, other)\n",
      " |  \n",
      " |  __itruediv__ = f(self, other)\n",
      " |  \n",
      " |  __ixor__ = f(self, other)\n",
      " |  \n",
      " |  __le__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      return the length of the Series\n",
      " |  \n",
      " |  __long__ = wrapper(self)\n",
      " |  \n",
      " |  __lt__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __matmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5\n",
      " |  \n",
      " |  __mod__ = wrapper(left, right)\n",
      " |  \n",
      " |  __mul__ = wrapper(left, right)\n",
      " |  \n",
      " |  __ne__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __or__ = wrapper(self, other)\n",
      " |  \n",
      " |  __pow__ = wrapper(left, right)\n",
      " |  \n",
      " |  __radd__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rand__ = wrapper(self, other)\n",
      " |  \n",
      " |  __rdiv__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rfloordiv__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rmatmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5\n",
      " |  \n",
      " |  __rmod__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rmul__ = wrapper(left, right)\n",
      " |  \n",
      " |  __ror__ = wrapper(self, other)\n",
      " |  \n",
      " |  __rpow__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rsub__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rtruediv__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rxor__ = wrapper(self, other)\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  __sub__ = wrapper(left, right)\n",
      " |  \n",
      " |  __truediv__ = wrapper(left, right)\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Return a string representation for a particular DataFrame\n",
      " |      \n",
      " |      Invoked by unicode(df) in py2 only. Yields a Unicode String in both\n",
      " |      py2/py3.\n",
      " |  \n",
      " |  __xor__ = wrapper(self, other)\n",
      " |  \n",
      " |  add(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Addition of series and other, element-wise (binary operator `add`).\n",
      " |      \n",
      " |      Equivalent to ``series + other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.radd\n",
      " |  \n",
      " |  agg = aggregate(self, func, axis=0, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, string, dictionary, or list of string/functions\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a Series or when passed to Series.apply. For\n",
      " |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - string function name.\n",
      " |          - function.\n",
      " |          - list of functions.\n",
      " |          - dict of column names -> functions (or list of functions).\n",
      " |      \n",
      " |      \n",
      " |      axis : {0 or 'index'}\n",
      " |          Parameter needed for compatibility with DataFrame.\n",
      " |      \n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      aggregated : Series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = Series(np.random.randn(10))\n",
      " |      \n",
      " |      >>> s.agg('min')\n",
      " |      -1.3018049988556679\n",
      " |      \n",
      " |      >>> s.agg(['min', 'max'])\n",
      " |      min   -1.301805\n",
      " |      max    1.127688\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.apply\n",
      " |      pandas.Series.transform\n",
      " |  \n",
      " |  aggregate(self, func, axis=0, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, string, dictionary, or list of string/functions\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a Series or when passed to Series.apply. For\n",
      " |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - string function name.\n",
      " |          - function.\n",
      " |          - list of functions.\n",
      " |          - dict of column names -> functions (or list of functions).\n",
      " |      \n",
      " |      \n",
      " |      axis : {0 or 'index'}\n",
      " |          Parameter needed for compatibility with DataFrame.\n",
      " |      \n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      aggregated : Series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = Series(np.random.randn(10))\n",
      " |      \n",
      " |      >>> s.agg('min')\n",
      " |      -1.3018049988556679\n",
      " |      \n",
      " |      >>> s.agg(['min', 'max'])\n",
      " |      min   -1.301805\n",
      " |      max    1.127688\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.apply\n",
      " |      pandas.Series.transform\n",
      " |  \n",
      " |  align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)\n",
      " |      Align two objects on their axes with the\n",
      " |      specified join method for each axis Index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None)\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      copy : boolean, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      method : str, default None\n",
      " |      limit : int, default None\n",
      " |      fill_axis : {0 or 'index'}, default 0\n",
      " |          Filling axis, method and limit\n",
      " |      broadcast_axis : {0 or 'index'}, default None\n",
      " |          Broadcast values along this axis, if aligning two objects of\n",
      " |          different dimensions\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (left, right) : (Series, type of other)\n",
      " |          Aligned objects\n",
      " |  \n",
      " |  all(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether all elements are True, potentially over an axis.\n",
      " |      \n",
      " |      Returns True if all elements within a series or along a Dataframe\n",
      " |      axis are non-zero, not-empty or not-False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      all : scalar or Series (if level specified)\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.all : Return True if all elements are True\n",
      " |      pandas.DataFrame.any : Return True if one (or more) elements are True\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Series\n",
      " |      \n",
      " |      >>> pd.Series([True, True]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([True, False]).all()\n",
      " |      False\n",
      " |      \n",
      " |      DataFrames\n",
      " |      \n",
      " |      Create a dataframe from a dictionary.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
      " |      >>> df\n",
      " |         col1   col2\n",
      " |      0  True   True\n",
      " |      1  True  False\n",
      " |      \n",
      " |      Default behaviour checks if column-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all()\n",
      " |      col1     True\n",
      " |      col2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Specify ``axis='columns'`` to check if row-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all(axis='columns')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Or ``axis=None`` for whether every value is True.\n",
      " |      \n",
      " |      >>> df.all(axis=None)\n",
      " |      False\n",
      " |  \n",
      " |  any(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether any element is True over requested axis.\n",
      " |      \n",
      " |      Unlike :meth:`DataFrame.all`, this performs an *or* operation. If any of the\n",
      " |      values along the specified axis is True, this will return True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      any : scalar or Series (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.all : Return whether all elements are True.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      For Series input, the output is a scalar indicating whether any element\n",
      " |      is True.\n",
      " |      \n",
      " |      >>> pd.Series([True, False]).any()\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Whether each column contains at least one True element (the default).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  1  0  0\n",
      " |      1  2  2  0\n",
      " |      \n",
      " |      >>> df.any()\n",
      " |      A     True\n",
      " |      B     True\n",
      " |      C    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  2\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  0\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the entire DataFrame with ``axis=None``.\n",
      " |      \n",
      " |      >>> df.any(axis=None)\n",
      " |      True\n",
      " |      \n",
      " |      `any` for an empty DataFrame is an empty Series.\n",
      " |      \n",
      " |      >>> pd.DataFrame([]).any()\n",
      " |      Series([], dtype: bool)\n",
      " |  \n",
      " |  append(self, to_append, ignore_index=False, verify_integrity=False)\n",
      " |      Concatenate two or more Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_append : Series or list/tuple of Series\n",
      " |      ignore_index : boolean, default False\n",
      " |          If True, do not use the index labels.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      verify_integrity : boolean, default False\n",
      " |          If True, raise Exception on creating index with duplicates\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Iteratively appending to a Series can be more computationally intensive\n",
      " |      than a single concatenate. A better solution is to append values to a\n",
      " |      list and then concatenate the list with the original Series all at\n",
      " |      once.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.concat : General function to concatenate DataFrame, Series\n",
      " |          or Panel objects\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      appended : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([1, 2, 3])\n",
      " |      >>> s2 = pd.Series([4, 5, 6])\n",
      " |      >>> s3 = pd.Series([4, 5, 6], index=[3,4,5])\n",
      " |      >>> s1.append(s2)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s1.append(s3)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      5    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      With `ignore_index` set to True:\n",
      " |      \n",
      " |      >>> s1.append(s2, ignore_index=True)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      5    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      With `verify_integrity` set to True:\n",
      " |      \n",
      " |      >>> s1.append(s2, verify_integrity=True)\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: Indexes have overlapping values: [0, 1, 2]\n",
      " |  \n",
      " |  apply(self, func, convert_dtype=True, args=(), **kwds)\n",
      " |      Invoke function on values of Series. Can be ufunc (a NumPy function\n",
      " |      that applies to the entire Series) or a Python function that only works\n",
      " |      on single values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |      convert_dtype : boolean, default True\n",
      " |          Try to find better dtype for elementwise function results. If\n",
      " |          False, leave as dtype=object\n",
      " |      args : tuple\n",
      " |          Positional arguments to pass to function in addition to the value\n",
      " |      Additional keyword arguments will be passed as keywords to the function\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series or DataFrame if func returns a Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.map: For element-wise operations\n",
      " |      Series.agg: only perform aggregating type operations\n",
      " |      Series.transform: only perform transformating type operations\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create a series with typical summer temperatures for each city.\n",
      " |      \n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> series = pd.Series([20, 21, 12], index=['London',\n",
      " |      ... 'New York','Helsinki'])\n",
      " |      >>> series\n",
      " |      London      20\n",
      " |      New York    21\n",
      " |      Helsinki    12\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Square the values by defining a function and passing it as an\n",
      " |      argument to ``apply()``.\n",
      " |      \n",
      " |      >>> def square(x):\n",
      " |      ...     return x**2\n",
      " |      >>> series.apply(square)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Square the values by passing an anonymous function as an\n",
      " |      argument to ``apply()``.\n",
      " |      \n",
      " |      >>> series.apply(lambda x: x**2)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Define a custom function that needs additional positional\n",
      " |      arguments and pass these additional arguments using the\n",
      " |      ``args`` keyword.\n",
      " |      \n",
      " |      >>> def subtract_custom_value(x, custom_value):\n",
      " |      ...     return x-custom_value\n",
      " |      \n",
      " |      >>> series.apply(subtract_custom_value, args=(5,))\n",
      " |      London      15\n",
      " |      New York    16\n",
      " |      Helsinki     7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Define a custom function that takes keyword arguments\n",
      " |      and pass these arguments to ``apply``.\n",
      " |      \n",
      " |      >>> def add_custom_values(x, **kwargs):\n",
      " |      ...     for month in kwargs:\n",
      " |      ...         x+=kwargs[month]\n",
      " |      ...     return x\n",
      " |      \n",
      " |      >>> series.apply(add_custom_values, june=30, july=20, august=25)\n",
      " |      London      95\n",
      " |      New York    96\n",
      " |      Helsinki    87\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Use a function from the Numpy library.\n",
      " |      \n",
      " |      >>> series.apply(np.log)\n",
      " |      London      2.995732\n",
      " |      New York    3.044522\n",
      " |      Helsinki    2.484907\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  argmax = idxmax(self, axis=0, skipna=True, *args, **kwargs)\n",
      " |      .. deprecated:: 0.21.0\n",
      " |      \n",
      " |         'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      " |          will be corrected to return the positional maximum in the future. Use\n",
      " |          'series.values.argmax' to get the position of the maximum now.\n",
      " |      \n",
      " |      \n",
      " |      Return the row label of the maximum value.\n",
      " |      \n",
      " |      If multiple values equal the maximum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmax. Redundant for application\n",
      " |          on Series.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywors have no effect but might be accepted\n",
      " |          for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Index of maximum of values.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmax``. This method\n",
      " |      returns the label of the maximum, while ``ndarray.argmax`` returns\n",
      " |      the position. To get the position, use ``series.values.argmax()``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmax : Return indices of the maximum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmax : Return index of first occurrence of maximum\n",
      " |          over requested axis.\n",
      " |      Series.idxmin : Return index *label* of the first occurrence\n",
      " |          of minimum of values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 3, 4],\n",
      " |      ...               index=['A', 'B', 'C', 'D', 'E'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    3.0\n",
      " |      E    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmax()\n",
      " |      'C'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmax(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  argmin = idxmin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      .. deprecated:: 0.21.0\n",
      " |      \n",
      " |         'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      " |          will be corrected to return the positional minimum in the future. Use\n",
      " |          'series.values.argmin' to get the position of the minimum now.\n",
      " |      \n",
      " |      \n",
      " |      Return the row label of the minimum value.\n",
      " |      \n",
      " |      If multiple values equal the minimum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmin. Redundant for application\n",
      " |          on Series.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywors have no effect but might be accepted\n",
      " |          for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Index of minimum of values.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmin``. This method\n",
      " |      returns the label of the minimum, while ``ndarray.argmin`` returns\n",
      " |      the position. To get the position, use ``series.values.argmin()``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmin : Return indices of the minimum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmin : Return index of first occurrence of minimum\n",
      " |          over requested axis.\n",
      " |      Series.idxmax : Return index *label* of the first occurrence\n",
      " |          of maximum of values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 1],\n",
      " |      ...               index=['A' ,'B' ,'C' ,'D'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmin()\n",
      " |      'A'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmin(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  argsort(self, axis=0, kind='quicksort', order=None)\n",
      " |      Overrides ndarray.argsort. Argsorts the value, omitting NA/null values,\n",
      " |      and places the result in the same locations as the non-NA values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int (can only be zero)\n",
      " |      kind : {'mergesort', 'quicksort', 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See np.sort for more\n",
      " |          information. 'mergesort' is the only stable algorithm\n",
      " |      order : ignored\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      argsorted : Series, with -1 indicated where nan values are present\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.argsort\n",
      " |  \n",
      " |  autocorr(self, lag=1)\n",
      " |      Lag-N autocorrelation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lag : int, default 1\n",
      " |          Number of lags to apply before performing autocorrelation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      autocorr : float\n",
      " |  \n",
      " |  between(self, left, right, inclusive=True)\n",
      " |      Return boolean Series equivalent to left <= series <= right.\n",
      " |      \n",
      " |      This function returns a boolean vector containing `True` wherever the\n",
      " |      corresponding Series element is between the boundary values `left` and\n",
      " |      `right`. NA values are treated as `False`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      left : scalar\n",
      " |          Left boundary.\n",
      " |      right : scalar\n",
      " |          Right boundary.\n",
      " |      inclusive : bool, default True\n",
      " |          Include boundaries.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Each element will be a boolean.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function is equivalent to ``(left <= ser) & (ser <= right)``\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.gt : Greater than of series and other\n",
      " |      pandas.Series.lt : Less than of series and other\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([2, 0, 4, 8, np.nan])\n",
      " |      \n",
      " |      Boundary values are included by default:\n",
      " |      \n",
      " |      >>> s.between(1, 4)\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      With `inclusive` set to ``False`` boundary values are excluded:\n",
      " |      \n",
      " |      >>> s.between(1, 4, inclusive=False)\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      `left` and `right` can be any scalar value:\n",
      " |      \n",
      " |      >>> s = pd.Series(['Alice', 'Bob', 'Carol', 'Eve'])\n",
      " |      >>> s.between('Anna', 'Daniel')\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  combine(self, other, func, fill_value=nan)\n",
      " |      Perform elementwise binary operation on two Series using given function\n",
      " |      with optional fill value when an index is missing from one Series or\n",
      " |      the other\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      func : function\n",
      " |          Function that takes two scalars as inputs and return a scalar\n",
      " |      fill_value : scalar value\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = Series([1, 2])\n",
      " |      >>> s2 = Series([0, 3])\n",
      " |      >>> s1.combine(s2, lambda x1, x2: x1 if x1 < x2 else x2)\n",
      " |      0    0\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.combine_first : Combine Series values, choosing the calling\n",
      " |          Series's values first\n",
      " |  \n",
      " |  combine_first(self, other)\n",
      " |      Combine Series values, choosing the calling Series's values\n",
      " |      first. Result index will be the union of the two indexes\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      combined : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([1, np.nan])\n",
      " |      >>> s2 = pd.Series([3, 4])\n",
      " |      >>> s1.combine_first(s2)\n",
      " |      0    1.0\n",
      " |      1    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.combine : Perform elementwise operation on two Series\n",
      " |          using a given function\n",
      " |  \n",
      " |  compound(self, axis=None, skipna=None, level=None)\n",
      " |      Return the compound percentage of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      compounded : scalar or Series (if level specified)\n",
      " |  \n",
      " |  compress(self, condition, *args, **kwargs)\n",
      " |      Return selected slices of an array along given axis as a Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.compress\n",
      " |  \n",
      " |  corr(self, other, method='pearson', min_periods=None)\n",
      " |      Compute correlation with `other` Series, excluding missing values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      method : {'pearson', 'kendall', 'spearman'}\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      correlation : float\n",
      " |  \n",
      " |  count(self, level=None)\n",
      " |      Return number of non-NA/null observations in the Series\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a smaller Series\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nobs : int or Series (if level specified)\n",
      " |  \n",
      " |  cov(self, other, min_periods=None)\n",
      " |      Compute covariance with Series, excluding missing values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      covariance : float\n",
      " |      \n",
      " |      Normalized by N-1 (unbiased estimator).\n",
      " |  \n",
      " |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative maximum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      maximum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cummax : scalar or Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummax()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3    5.0\n",
      " |      4    5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummax(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the maximum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummax()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  3.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the maximum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummax(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.max : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.max : Return the maximum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |  \n",
      " |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative minimum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      minimum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cummin : scalar or Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummin()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    2.0\n",
      " |      3   -1.0\n",
      " |      4   -1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummin(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the minimum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummin()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  2.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the minimum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummin(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.min : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.min : Return the minimum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |  \n",
      " |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative product over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      product.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cumprod : scalar or Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumprod()\n",
      " |      0     2.0\n",
      " |      1     NaN\n",
      " |      2    10.0\n",
      " |      3   -10.0\n",
      " |      4    -0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumprod(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the product\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumprod()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  6.0  NaN\n",
      " |      2  6.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the product in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumprod(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.prod : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.prod : Return the product over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |  \n",
      " |  cumsum(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative sum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      sum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cumsum : scalar or Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumsum()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    7.0\n",
      " |      3    6.0\n",
      " |      4    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumsum(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the sum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumsum()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  5.0  NaN\n",
      " |      2  6.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the sum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumsum(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.sum : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.sum : Return the sum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |  \n",
      " |  diff(self, periods=1)\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a Series element compared with another\n",
      " |      element in the Series (default is element in previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      diffed : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pct_change: Percent change over given number of periods.\n",
      " |      Series.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      DataFrame.diff: First discrete difference of object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 1, 2, 3, 5, 8])\n",
      " |      >>> s.diff()\n",
      " |      0    NaN\n",
      " |      1    0.0\n",
      " |      2    1.0\n",
      " |      3    1.0\n",
      " |      4    2.0\n",
      " |      5    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> s.diff(periods=3)\n",
      " |      0    NaN\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    2.0\n",
      " |      4    4.0\n",
      " |      5    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> s.diff(periods=-1)\n",
      " |      0    0.0\n",
      " |      1   -1.0\n",
      " |      2   -1.0\n",
      " |      3   -2.0\n",
      " |      4   -3.0\n",
      " |      5    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  div = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rtruediv\n",
      " |  \n",
      " |  divide = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rtruediv\n",
      " |  \n",
      " |  divmod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Integer division and modulo of series and other, element-wise (binary operator `divmod`).\n",
      " |      \n",
      " |      Equivalent to ``series divmod other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  dot(self, other)\n",
      " |      Matrix multiplication with DataFrame or inner-product with Series\n",
      " |      objects. Can also be called using `self @ other` in Python >= 3.5.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dot_product : scalar or Series\n",
      " |  \n",
      " |  drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
      " |      Return Series with specified index labels removed.\n",
      " |      \n",
      " |      Remove elements of a Series based on specifying the index labels.\n",
      " |      When using a multi-index, labels on different levels can be removed\n",
      " |      by specifying the level.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |          Index labels to drop.\n",
      " |      axis : 0, default 0\n",
      " |          Redundant for application on Series.\n",
      " |      index, columns : None\n",
      " |          Redundant for application on Series, but index can be used instead\n",
      " |          of labels.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      level : int or level name, optional\n",
      " |          For MultiIndex, level for which the labels will be removed.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and only existing labels are dropped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dropped : pandas.Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.reindex : Return only specified index labels of Series.\n",
      " |      Series.dropna : Return series without null values.\n",
      " |      Series.drop_duplicates : Return Series with duplicate values removed.\n",
      " |      DataFrame.drop : Drop specified labels from rows or columns.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If none of the labels are found in the index.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=np.arange(3), index=['A','B','C'])\n",
      " |      >>> s\n",
      " |      A  0\n",
      " |      B  1\n",
      " |      C  2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Drop labels B en C\n",
      " |      \n",
      " |      >>> s.drop(labels=['B','C'])\n",
      " |      A  0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Drop 2nd level label in MultiIndex Series\n",
      " |      \n",
      " |      >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
      " |      ...                              ['speed', 'weight', 'length']],\n",
      " |      ...                      labels=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      " |      ...                              [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      " |      >>> s = pd.Series([45, 200, 1.2, 30, 250, 1.5, 320, 1, 0.3],\n",
      " |      ...               index=midx)\n",
      " |      >>> s\n",
      " |      lama    speed      45.0\n",
      " |              weight    200.0\n",
      " |              length      1.2\n",
      " |      cow     speed      30.0\n",
      " |              weight    250.0\n",
      " |              length      1.5\n",
      " |      falcon  speed     320.0\n",
      " |              weight      1.0\n",
      " |              length      0.3\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.drop(labels='weight', level=1)\n",
      " |      lama    speed      45.0\n",
      " |              length      1.2\n",
      " |      cow     speed      30.0\n",
      " |              length      1.5\n",
      " |      falcon  speed     320.0\n",
      " |              length      0.3\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  drop_duplicates(self, keep='first', inplace=False)\n",
      " |      Return Series with duplicate values removed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', ``False``}, default 'first'\n",
      " |          - 'first' : Drop duplicates except for the first occurrence.\n",
      " |          - 'last' : Drop duplicates except for the last occurrence.\n",
      " |          - ``False`` : Drop all duplicates.\n",
      " |      inplace : boolean, default ``False``\n",
      " |          If ``True``, performs operation inplace and returns None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      deduplicated : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.drop_duplicates : equivalent method on Index\n",
      " |      DataFrame.drop_duplicates : equivalent method on DataFrame\n",
      " |      Series.duplicated : related method on Series, indicating duplicate\n",
      " |          Series values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Generate an Series with duplicated entries.\n",
      " |      \n",
      " |      >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama', 'hippo'],\n",
      " |      ...               name='animal')\n",
      " |      >>> s\n",
      " |      0      lama\n",
      " |      1       cow\n",
      " |      2      lama\n",
      " |      3    beetle\n",
      " |      4      lama\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |      \n",
      " |      With the 'keep' parameter, the selection behaviour of duplicated values\n",
      " |      can be changed. The value 'first' keeps the first occurrence for each\n",
      " |      set of duplicated entries. The default value of keep is 'first'.\n",
      " |      \n",
      " |      >>> s.drop_duplicates()\n",
      " |      0      lama\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |      \n",
      " |      The value 'last' for parameter 'keep' keeps the last occurrence for\n",
      " |      each set of duplicated entries.\n",
      " |      \n",
      " |      >>> s.drop_duplicates(keep='last')\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      4      lama\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |      \n",
      " |      The value ``False`` for parameter 'keep' discards all sets of\n",
      " |      duplicated entries. Setting the value of 'inplace' to ``True`` performs\n",
      " |      the operation inplace and returns ``None``.\n",
      " |      \n",
      " |      >>> s.drop_duplicates(keep=False, inplace=True)\n",
      " |      >>> s\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |  \n",
      " |  dropna(self, axis=0, inplace=False, **kwargs)\n",
      " |      Return a new Series with missing values removed.\n",
      " |      \n",
      " |      See the :ref:`User Guide <missing_data>` for more on which values are\n",
      " |      considered missing, and how to work with missing data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'}, default 0\n",
      " |          There is only one axis to drop values from.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      **kwargs\n",
      " |          Not in use.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series with NA entries dropped from it.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isna: Indicate missing values.\n",
      " |      Series.notna : Indicate existing (non-missing) values.\n",
      " |      Series.fillna : Replace missing values.\n",
      " |      DataFrame.dropna : Drop rows or columns which contain NA values.\n",
      " |      Index.dropna : Drop missing indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1., 2., np.nan])\n",
      " |      >>> ser\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Drop NA values from a Series.\n",
      " |      \n",
      " |      >>> ser.dropna()\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Keep the Series with valid entries in the same variable.\n",
      " |      \n",
      " |      >>> ser.dropna(inplace=True)\n",
      " |      >>> ser\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Empty strings are not considered NA values. ``None`` is considered an\n",
      " |      NA value.\n",
      " |      \n",
      " |      >>> ser = pd.Series([np.NaN, 2, pd.NaT, '', None, 'I stay'])\n",
      " |      >>> ser\n",
      " |      0       NaN\n",
      " |      1         2\n",
      " |      2       NaT\n",
      " |      3\n",
      " |      4      None\n",
      " |      5    I stay\n",
      " |      dtype: object\n",
      " |      >>> ser.dropna()\n",
      " |      1         2\n",
      " |      3\n",
      " |      5    I stay\n",
      " |      dtype: object\n",
      " |  \n",
      " |  duplicated(self, keep='first')\n",
      " |      Indicate duplicate Series values.\n",
      " |      \n",
      " |      Duplicated values are indicated as ``True`` values in the resulting\n",
      " |      Series. Either all duplicates, all except the first or all except the\n",
      " |      last occurrence of duplicates can be indicated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          - 'first' : Mark duplicates as ``True`` except for the first\n",
      " |            occurrence.\n",
      " |          - 'last' : Mark duplicates as ``True`` except for the last\n",
      " |            occurrence.\n",
      " |          - ``False`` : Mark all duplicates as ``True``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, for each set of duplicated values, the first occurrence is\n",
      " |      set on False and all others on True:\n",
      " |      \n",
      " |      >>> animals = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama'])\n",
      " |      >>> animals.duplicated()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      which is equivalent to\n",
      " |      \n",
      " |      >>> animals.duplicated(keep='first')\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By using 'last', the last occurrence of each set of duplicated values\n",
      " |      is set on False and all others on True:\n",
      " |      \n",
      " |      >>> animals.duplicated(keep='last')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By setting keep on ``False``, all duplicates are True:\n",
      " |      \n",
      " |      >>> animals.duplicated(keep=False)\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.core.series.Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Index.duplicated : Equivalent method on pandas.Index\n",
      " |      pandas.DataFrame.duplicated : Equivalent method on pandas.DataFrame\n",
      " |      pandas.Series.drop_duplicates : Remove duplicate values from Series\n",
      " |  \n",
      " |  eq(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Equal to of series and other, element-wise (binary operator `eq`).\n",
      " |      \n",
      " |      Equivalent to ``series == other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  ewm(self, com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=0)\n",
      " |      Provides exponential weighted functions\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      com : float, optional\n",
      " |          Specify decay in terms of center of mass,\n",
      " |          :math:`\\alpha = 1 / (1 + com),\\text{ for } com \\geq 0`\n",
      " |      span : float, optional\n",
      " |          Specify decay in terms of span,\n",
      " |          :math:`\\alpha = 2 / (span + 1),\\text{ for } span \\geq 1`\n",
      " |      halflife : float, optional\n",
      " |          Specify decay in terms of half-life,\n",
      " |          :math:`\\alpha = 1 - exp(log(0.5) / halflife),\\text{ for } halflife > 0`\n",
      " |      alpha : float, optional\n",
      " |          Specify smoothing factor :math:`\\alpha` directly,\n",
      " |          :math:`0 < \\alpha \\leq 1`\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      min_periods : int, default 0\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      adjust : boolean, default True\n",
      " |          Divide by decaying adjustment factor in beginning periods to account\n",
      " |          for imbalance in relative weightings (viewing EWMA as a moving average)\n",
      " |      ignore_na : boolean, default False\n",
      " |          Ignore missing values when calculating weights;\n",
      " |          specify True to reproduce pre-0.15.0 behavior\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Exactly one of center of mass, span, half-life, and alpha must be provided.\n",
      " |      Allowed values and relationship between the parameters are specified in the\n",
      " |      parameter descriptions above; see the link at the end of this section for\n",
      " |      a detailed explanation.\n",
      " |      \n",
      " |      When adjust is True (default), weighted averages are calculated using\n",
      " |      weights (1-alpha)**(n-1), (1-alpha)**(n-2), ..., 1-alpha, 1.\n",
      " |      \n",
      " |      When adjust is False, weighted averages are calculated recursively as:\n",
      " |         weighted_average[0] = arg[0];\n",
      " |         weighted_average[i] = (1-alpha)*weighted_average[i-1] + alpha*arg[i].\n",
      " |      \n",
      " |      When ignore_na is False (default), weights are based on absolute positions.\n",
      " |      For example, the weights of x and y used in calculating the final weighted\n",
      " |      average of [x, None, y] are (1-alpha)**2 and 1 (if adjust is True), and\n",
      " |      (1-alpha)**2 and alpha (if adjust is False).\n",
      " |      \n",
      " |      When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based\n",
      " |      on relative positions. For example, the weights of x and y used in\n",
      " |      calculating the final weighted average of [x, None, y] are 1-alpha and 1\n",
      " |      (if adjust is True), and 1-alpha and alpha (if adjust is False).\n",
      " |      \n",
      " |      More details can be found at\n",
      " |      http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations\n",
      " |      expanding : Provides expanding transformations.\n",
      " |  \n",
      " |  expanding(self, min_periods=1, center=False, axis=0)\n",
      " |      Provides expanding transformations.\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, default 1\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      center : boolean, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      axis : int or string, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.expanding(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations\n",
      " |      ewm : Provides exponential weighted functions\n",
      " |  \n",
      " |  fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)\n",
      " |      Fill NA/NaN values using the specified method\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame). (values not\n",
      " |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill gap\n",
      " |      axis : {0 or 'index'}\n",
      " |      inplace : boolean, default False\n",
      " |          If True, fill in place. Note: this will modify any\n",
      " |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          a dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex, asfreq\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                    columns=list('ABCD'))\n",
      " |      >>> df\n",
      " |           A    B   C  D\n",
      " |      0  NaN  2.0 NaN  0\n",
      " |      1  3.0  4.0 NaN  1\n",
      " |      2  NaN  NaN NaN  5\n",
      " |      3  NaN  3.0 NaN  4\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 0.0 0\n",
      " |      1   3.0 4.0 0.0 1\n",
      " |      2   0.0 0.0 0.0 5\n",
      " |      3   0.0 3.0 0.0 4\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method='ffill')\n",
      " |          A   B   C   D\n",
      " |      0   NaN 2.0 NaN 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   3.0 4.0 NaN 5\n",
      " |      3   3.0 3.0 NaN 4\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 2.0 1\n",
      " |      2   0.0 1.0 2.0 5\n",
      " |      3   0.0 3.0 2.0 4\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   NaN 1.0 NaN 5\n",
      " |      3   NaN 3.0 NaN 4\n",
      " |  \n",
      " |  floordiv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Integer division of series and other, element-wise (binary operator `floordiv`).\n",
      " |      \n",
      " |      Equivalent to ``series // other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rfloordiv\n",
      " |  \n",
      " |  ge(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Greater than or equal to of series and other, element-wise (binary operator `ge`).\n",
      " |      \n",
      " |      Equivalent to ``series >= other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  get_value(self, label, takeable=False)\n",
      " |      Quickly retrieve single value at passed index label\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Please use .at[] or .iat[] accessors.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      label : object\n",
      " |      takeable : interpret the index as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : scalar value\n",
      " |  \n",
      " |  get_values(self)\n",
      " |      same as values (but handles sparseness conversions); is a view\n",
      " |  \n",
      " |  gt(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Greater than of series and other, element-wise (binary operator `gt`).\n",
      " |      \n",
      " |      Equivalent to ``series > other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  hist = hist_series(self, by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, figsize=None, bins=10, **kwds)\n",
      " |      Draw histogram of the input series using matplotlib\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups\n",
      " |      ax : matplotlib axis object\n",
      " |          If not passed, uses gca()\n",
      " |      grid : boolean, default True\n",
      " |          Whether to show axis grid lines\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size\n",
      " |      xrot : float, default None\n",
      " |          rotation of x axis labels\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size\n",
      " |      yrot : float, default None\n",
      " |          rotation of y axis labels\n",
      " |      figsize : tuple, default None\n",
      " |          figure size in inches by default\n",
      " |      bins : integer or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      bins: integer, default 10\n",
      " |          Number of histogram bins to be used\n",
      " |      `**kwds` : keywords\n",
      " |          To be passed to the actual plotting function\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.axes.Axes.hist : Plot a histogram using matplotlib.\n",
      " |  \n",
      " |  idxmax(self, axis=0, skipna=True, *args, **kwargs)\n",
      " |      Return the row label of the maximum value.\n",
      " |      \n",
      " |      If multiple values equal the maximum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmax. Redundant for application\n",
      " |          on Series.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywors have no effect but might be accepted\n",
      " |          for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Index of maximum of values.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmax``. This method\n",
      " |      returns the label of the maximum, while ``ndarray.argmax`` returns\n",
      " |      the position. To get the position, use ``series.values.argmax()``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmax : Return indices of the maximum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmax : Return index of first occurrence of maximum\n",
      " |          over requested axis.\n",
      " |      Series.idxmin : Return index *label* of the first occurrence\n",
      " |          of minimum of values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 3, 4],\n",
      " |      ...               index=['A', 'B', 'C', 'D', 'E'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    3.0\n",
      " |      E    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmax()\n",
      " |      'C'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmax(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  idxmin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return the row label of the minimum value.\n",
      " |      \n",
      " |      If multiple values equal the minimum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmin. Redundant for application\n",
      " |          on Series.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywors have no effect but might be accepted\n",
      " |          for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Index of minimum of values.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmin``. This method\n",
      " |      returns the label of the minimum, while ``ndarray.argmin`` returns\n",
      " |      the position. To get the position, use ``series.values.argmin()``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmin : Return indices of the minimum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmin : Return index of first occurrence of minimum\n",
      " |          over requested axis.\n",
      " |      Series.idxmax : Return index *label* of the first occurrence\n",
      " |          of maximum of values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 1],\n",
      " |      ...               index=['A' ,'B' ,'C' ,'D'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmin()\n",
      " |      'A'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmin(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  isin(self, values)\n",
      " |      Check whether `values` are contained in Series.\n",
      " |      \n",
      " |      Return a boolean Series showing whether each element in the Series\n",
      " |      matches an element in the passed sequence of `values` exactly.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : set or list-like\n",
      " |          The sequence of values to test. Passing in a single string will\n",
      " |          raise a ``TypeError``. Instead, turn a single string into a\n",
      " |          list of one element.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |      \n",
      " |            Support for values as a set.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      isin : Series (bool dtype)\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |        * If `values` is a string\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.isin : equivalent method on DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama',\n",
      " |      ...                'hippo'], name='animal')\n",
      " |      >>> s.isin(['cow', 'lama'])\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      5    False\n",
      " |      Name: animal, dtype: bool\n",
      " |      \n",
      " |      Passing a single string as ``s.isin('lama')`` will raise an error. Use\n",
      " |      a list of one element instead:\n",
      " |      \n",
      " |      >>> s.isin(['lama'])\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      5    False\n",
      " |      Name: animal, dtype: bool\n",
      " |  \n",
      " |  isna(self)\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isnull : alias of isna\n",
      " |      Series.notna : boolean inverse of isna\n",
      " |      Series.dropna : omit axes labels with missing values\n",
      " |      isna : top-level isna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  isnull(self)\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isnull : alias of isna\n",
      " |      Series.notna : boolean inverse of isna\n",
      " |      Series.dropna : omit axes labels with missing values\n",
      " |      isna : top-level isna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  items = iteritems(self)\n",
      " |      Lazily iterate over (index, value) tuples\n",
      " |  \n",
      " |  iteritems(self)\n",
      " |      Lazily iterate over (index, value) tuples\n",
      " |  \n",
      " |  keys(self)\n",
      " |      Alias for index\n",
      " |  \n",
      " |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      kurt : scalar or Series (if level specified)\n",
      " |  \n",
      " |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      kurt : scalar or Series (if level specified)\n",
      " |  \n",
      " |  le(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Less than or equal to of series and other, element-wise (binary operator `le`).\n",
      " |      \n",
      " |      Equivalent to ``series <= other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  lt(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Less than of series and other, element-wise (binary operator `lt`).\n",
      " |      \n",
      " |      Equivalent to ``series < other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  mad(self, axis=None, skipna=None, level=None)\n",
      " |      Return the mean absolute deviation of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mad : scalar or Series (if level specified)\n",
      " |  \n",
      " |  map(self, arg, na_action=None)\n",
      " |      Map values of Series using input correspondence (a dict, Series, or\n",
      " |      function).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg : function, dict, or Series\n",
      " |          Mapping correspondence.\n",
      " |      na_action : {None, 'ignore'}\n",
      " |          If 'ignore', propagate NA values, without passing them to the\n",
      " |          mapping correspondence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series\n",
      " |          Same index as caller.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Map inputs to outputs (both of type `Series`):\n",
      " |      \n",
      " |      >>> x = pd.Series([1,2,3], index=['one', 'two', 'three'])\n",
      " |      >>> x\n",
      " |      one      1\n",
      " |      two      2\n",
      " |      three    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> y = pd.Series(['foo', 'bar', 'baz'], index=[1,2,3])\n",
      " |      >>> y\n",
      " |      1    foo\n",
      " |      2    bar\n",
      " |      3    baz\n",
      " |      \n",
      " |      >>> x.map(y)\n",
      " |      one   foo\n",
      " |      two   bar\n",
      " |      three baz\n",
      " |      \n",
      " |      If `arg` is a dictionary, return a new Series with values converted\n",
      " |      according to the dictionary's mapping:\n",
      " |      \n",
      " |      >>> z = {1: 'A', 2: 'B', 3: 'C'}\n",
      " |      \n",
      " |      >>> x.map(z)\n",
      " |      one   A\n",
      " |      two   B\n",
      " |      three C\n",
      " |      \n",
      " |      Use na_action to control whether NA values are affected by the mapping\n",
      " |      function.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, np.nan])\n",
      " |      \n",
      " |      >>> s2 = s.map('this is a string {}'.format, na_action=None)\n",
      " |      0    this is a string 1.0\n",
      " |      1    this is a string 2.0\n",
      " |      2    this is a string 3.0\n",
      " |      3    this is a string nan\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s3 = s.map('this is a string {}'.format, na_action='ignore')\n",
      " |      0    this is a string 1.0\n",
      " |      1    this is a string 2.0\n",
      " |      2    this is a string 3.0\n",
      " |      3                     NaN\n",
      " |      dtype: object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.apply : For applying more complex functions on a Series.\n",
      " |      DataFrame.apply : Apply a function row-/column-wise.\n",
      " |      DataFrame.applymap : Apply a function elementwise on a whole DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When `arg` is a dictionary, values in Series that are not in the\n",
      " |      dictionary (as keys) are converted to ``NaN``. However, if the\n",
      " |      dictionary is a ``dict`` subclass that defines ``__missing__`` (i.e.\n",
      " |      provides a method for default values), then this default is used\n",
      " |      rather than ``NaN``:\n",
      " |      \n",
      " |      >>> from collections import Counter\n",
      " |      >>> counter = Counter()\n",
      " |      >>> counter['bar'] += 1\n",
      " |      >>> y.map(counter)\n",
      " |      1    0\n",
      " |      2    1\n",
      " |      3    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the maximum of the values in the object.\n",
      " |                  If you want the *index* of the maximum, use ``idxmax``. This is\n",
      " |                  the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      max : scalar or Series (if level specified)\n",
      " |  \n",
      " |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the mean of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mean : scalar or Series (if level specified)\n",
      " |  \n",
      " |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the median of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      median : scalar or Series (if level specified)\n",
      " |  \n",
      " |  memory_usage(self, index=True, deep=False)\n",
      " |      Return the memory usage of the Series.\n",
      " |      \n",
      " |      The memory usage can optionally include the contribution of\n",
      " |      the index and of elements of `object` dtype.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Specifies whether to include the memory usage of the Series index.\n",
      " |      deep : bool, default False\n",
      " |          If True, introspect the data deeply by interrogating\n",
      " |          `object` dtypes for system-level memory consumption, and include\n",
      " |          it in the returned value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          Bytes of memory consumed.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes : Total bytes consumed by the elements of the\n",
      " |          array.\n",
      " |      DataFrame.memory_usage : Bytes consumed by a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3))\n",
      " |      >>> s.memory_usage()\n",
      " |      104\n",
      " |      \n",
      " |      Not including the index gives the size of the rest of the data, which\n",
      " |      is necessarily smaller:\n",
      " |      \n",
      " |      >>> s.memory_usage(index=False)\n",
      " |      24\n",
      " |      \n",
      " |      The memory footprint of `object` values is ignored by default:\n",
      " |      \n",
      " |      >>> s = pd.Series([\"a\", \"b\"])\n",
      " |      >>> s.values\n",
      " |      array(['a', 'b'], dtype=object)\n",
      " |      >>> s.memory_usage()\n",
      " |      96\n",
      " |      >>> s.memory_usage(deep=True)\n",
      " |      212\n",
      " |  \n",
      " |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the minimum of the values in the object.\n",
      " |                  If you want the *index* of the minimum, use ``idxmin``. This is\n",
      " |                  the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      min : scalar or Series (if level specified)\n",
      " |  \n",
      " |  mod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Modulo of series and other, element-wise (binary operator `mod`).\n",
      " |      \n",
      " |      Equivalent to ``series % other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rmod\n",
      " |  \n",
      " |  mode(self)\n",
      " |      Return the mode(s) of the dataset.\n",
      " |      \n",
      " |      Always returns Series even if only one value is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      modes : Series (sorted)\n",
      " |  \n",
      " |  mul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Multiplication of series and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rmul\n",
      " |  \n",
      " |  multiply = mul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Multiplication of series and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rmul\n",
      " |  \n",
      " |  ne(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Not equal to of series and other, element-wise (binary operator `ne`).\n",
      " |      \n",
      " |      Equivalent to ``series != other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  nlargest(self, n=5, keep='first')\n",
      " |      Return the largest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Return this many descending sorted values\n",
      " |      keep : {'first', 'last'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      top_n : Series\n",
      " |          The n largest values in the Series, in sorted order\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values(ascending=False).head(n)`` for small `n`\n",
      " |      relative to the size of the ``Series`` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nsmallest\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> s = pd.Series(np.random.randn(10**6))\n",
      " |      >>> s.nlargest(10)  # only sorts up to the N requested\n",
      " |      219921    4.644710\n",
      " |      82124     4.608745\n",
      " |      421689    4.564644\n",
      " |      425277    4.447014\n",
      " |      718691    4.414137\n",
      " |      43154     4.403520\n",
      " |      283187    4.313922\n",
      " |      595519    4.273635\n",
      " |      503969    4.250236\n",
      " |      121637    4.240952\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  nonzero(self)\n",
      " |      Return the *integer* indices of the elements that are non-zero\n",
      " |      \n",
      " |      This method is equivalent to calling `numpy.nonzero` on the\n",
      " |      series data. For compatibility with NumPy, the return value is\n",
      " |      the same (a tuple with an array of indices for each dimension),\n",
      " |      but it will always be a one-item tuple because series only have\n",
      " |      one dimension.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0, 3, 0, 4])\n",
      " |      >>> s.nonzero()\n",
      " |      (array([1, 3]),)\n",
      " |      >>> s.iloc[s.nonzero()[0]]\n",
      " |      1    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 3, 0, 4], index=['a', 'b', 'c', 'd'])\n",
      " |      # same return although index of s is different\n",
      " |      >>> s.nonzero()\n",
      " |      (array([1, 3]),)\n",
      " |      >>> s.iloc[s.nonzero()[0]]\n",
      " |      b    3\n",
      " |      d    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.nonzero\n",
      " |  \n",
      " |  notna(self)\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.notnull : alias of notna\n",
      " |      Series.isna : boolean inverse of notna\n",
      " |      Series.dropna : omit axes labels with missing values\n",
      " |      notna : top-level notna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  notnull(self)\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.notnull : alias of notna\n",
      " |      Series.isna : boolean inverse of notna\n",
      " |      Series.dropna : omit axes labels with missing values\n",
      " |      notna : top-level notna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  nsmallest(self, n=5, keep='first')\n",
      " |      Return the smallest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Return this many ascending sorted values\n",
      " |      keep : {'first', 'last'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bottom_n : Series\n",
      " |          The n smallest values in the Series, in sorted order\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values().head(n)`` for small `n` relative to\n",
      " |      the size of the ``Series`` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nlargest\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> s = pd.Series(np.random.randn(10**6))\n",
      " |      >>> s.nsmallest(10)  # only sorts up to the N requested\n",
      " |      288532   -4.954580\n",
      " |      732345   -4.835960\n",
      " |      64803    -4.812550\n",
      " |      446457   -4.609998\n",
      " |      501225   -4.483945\n",
      " |      669476   -4.472935\n",
      " |      973615   -4.401699\n",
      " |      621279   -4.355126\n",
      " |      773916   -4.347355\n",
      " |      359919   -4.331927\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  pow(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Exponential power of series and other, element-wise (binary operator `pow`).\n",
      " |      \n",
      " |      Equivalent to ``series ** other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rpow\n",
      " |  \n",
      " |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the product of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |          .. versionadded :: 0.22.0\n",
      " |      \n",
      " |             Added with the default being 0. This means the sum of an all-NA\n",
      " |             or empty Series is 0, and the product of an all-NA or empty\n",
      " |             Series is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prod : scalar or Series (if level specified)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the product of an empty or all-NA Series is ``1``\n",
      " |      \n",
      " |      >>> pd.Series([]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter\n",
      " |      \n",
      " |      >>> pd.Series([]).prod(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the product of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |          .. versionadded :: 0.22.0\n",
      " |      \n",
      " |             Added with the default being 0. This means the sum of an all-NA\n",
      " |             or empty Series is 0, and the product of an all-NA or empty\n",
      " |             Series is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prod : scalar or Series (if level specified)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the product of an empty or all-NA Series is ``1``\n",
      " |      \n",
      " |      >>> pd.Series([]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter\n",
      " |      \n",
      " |      >>> pd.Series([]).prod(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  ptp(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Returns the difference between the maximum value and the\n",
      " |                  minimum value in the object. This is the equivalent of the\n",
      " |                  ``numpy.ndarray`` method ``ptp``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ptp : scalar or Series (if level specified)\n",
      " |  \n",
      " |  put(self, *args, **kwargs)\n",
      " |      Applies the `put` method to its `values` attribute\n",
      " |      if it has one.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.put\n",
      " |  \n",
      " |  quantile(self, q=0.5, interpolation='linear')\n",
      " |      Return value at the given quantile, a la numpy.percentile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          0 <= q <= 1, the quantile(s) to compute\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |              * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |                fractional part of the index surrounded by `i` and `j`.\n",
      " |              * lower: `i`.\n",
      " |              * higher: `j`.\n",
      " |              * nearest: `i` or `j` whichever is nearest.\n",
      " |              * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      quantile : float or Series\n",
      " |          if ``q`` is an array, a Series will be returned where the\n",
      " |          index is ``q`` and the values are the quantiles.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = Series([1, 2, 3, 4])\n",
      " |      >>> s.quantile(.5)\n",
      " |      2.5\n",
      " |      >>> s.quantile([.25, .5, .75])\n",
      " |      0.25    1.75\n",
      " |      0.50    2.50\n",
      " |      0.75    3.25\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.core.window.Rolling.quantile\n",
      " |  \n",
      " |  radd(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Addition of series and other, element-wise (binary operator `radd`).\n",
      " |      \n",
      " |      Equivalent to ``other + series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.add\n",
      " |  \n",
      " |  ravel(self, order='C')\n",
      " |      Return the flattened underlying data as an ndarray\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.ravel\n",
      " |  \n",
      " |  rdiv = rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.truediv\n",
      " |  \n",
      " |  reindex(self, index=None, **kwargs)\n",
      " |      Conform Series to new index with optional filling logic, placing\n",
      " |      NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      copy=False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      index : array-like, optional (should be specified using keywords)\n",
      " |          New labels / index to conform to. Preferably an Index object to\n",
      " |          avoid duplicating data\n",
      " |      \n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      " |          method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * default: don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap\n",
      " |      \n",
      " |      copy : boolean, default True\n",
      " |          Return a new object, even if the passed indexes are the same\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      ``DataFrame.reindex`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      " |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Create a dataframe with some fictional data.\n",
      " |      \n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...      'http_status': [200,200,404,404,301],\n",
      " |      ...      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...       index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |      \n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |      \n",
      " |      >>> new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...             'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |      \n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |      \n",
      " |      We can also reindex the columns.\n",
      " |      \n",
      " |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      Or we can use \"axis-style\" keyword arguments\n",
      " |      \n",
      " |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |      \n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      \n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |      \n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |      \n",
      " |      For example, to backpropagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |      \n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29     100\n",
      " |      2009-12-30     100\n",
      " |      2009-12-31     100\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : Series\n",
      " |  \n",
      " |  reindex_axis(self, labels, axis=0, **kwargs)\n",
      " |      Conform Series to new index with optional filling logic.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use ``Series.reindex`` instead.\n",
      " |  \n",
      " |  rename(self, index=None, **kwargs)\n",
      " |      Alter Series index labels or name\n",
      " |      \n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      " |      error.\n",
      " |      \n",
      " |      Alternatively, change ``Series.name`` with a scalar value.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.rename>` for more.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : scalar, hashable sequence, dict-like or function, optional\n",
      " |          dict-like or functions are transformations to apply to\n",
      " |          the index.\n",
      " |          Scalar or hashable sequence-like will alter the ``Series.name``\n",
      " |          attribute.\n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to return a new Series. If True then value of copy is\n",
      " |          ignored.\n",
      " |      level : int or level name, default None\n",
      " |          In case of a MultiIndex, only rename labels in the specified\n",
      " |          level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Series (new object)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.rename_axis\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      >>> s.rename(\"my_name\") # scalar, changes Series.name\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      Name: my_name, dtype: int64\n",
      " |      >>> s.rename(lambda x: x ** 2)  # function, changes labels\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      >>> s.rename({1: 3, 2: 5})  # mapping, changes labels\n",
      " |      0    1\n",
      " |      3    2\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  reorder_levels(self, order)\n",
      " |      Rearrange index levels using input order. May not drop or duplicate\n",
      " |      levels\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int representing new level order.\n",
      " |             (reference level by number or key)\n",
      " |      axis : where to reorder levels\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller (new object)\n",
      " |  \n",
      " |  repeat(self, repeats, *args, **kwargs)\n",
      " |      Repeat elements of an Series. Refer to `numpy.ndarray.repeat`\n",
      " |      for more information about the `repeats` argument.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.repeat\n",
      " |  \n",
      " |  replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')\n",
      " |      Replace values given in `to_replace` with `value`.\n",
      " |      \n",
      " |      Values of the Series are replaced with other values dynamically.\n",
      " |      This differs from updating with ``.loc`` or ``.iloc``, which require\n",
      " |      you to specify a location to update with some value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, int, float, or None\n",
      " |          How to find the values that will be replaced.\n",
      " |      \n",
      " |          * numeric, str or regex:\n",
      " |      \n",
      " |              - numeric: numeric values equal to `to_replace` will be\n",
      " |                replaced with `value`\n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                `value`\n",
      " |      \n",
      " |          * list of str, regex, or numeric:\n",
      " |      \n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                lists will be interpreted as regexs otherwise they will match\n",
      " |                directly. This doesn't matter much for `value` since there\n",
      " |                are only a few possible substitution regexes you can use.\n",
      " |              - str, regex and numeric rules apply as above.\n",
      " |      \n",
      " |          * dict:\n",
      " |      \n",
      " |              - Dicts can be used to specify different replacement values\n",
      " |                for different existing values. For example,\n",
      " |                ``{'a': 'b', 'y': 'z'}`` replaces the value 'a' with 'b' and\n",
      " |                'y' with 'z'. To use a dict in this way the `value`\n",
      " |                parameter should be `None`.\n",
      " |              - For a DataFrame a dict can specify that different values\n",
      " |                should be replaced in different columns. For example,\n",
      " |                ``{'a': 1, 'b': 'z'}`` looks for the value 1 in column 'a'\n",
      " |                and the value 'z' in column 'b' and replaces these values\n",
      " |                with whatever is specified in `value`. The `value` parameter\n",
      " |                should not be ``None`` in this case. You can treat this as a\n",
      " |                special case of passing two lists except that you are\n",
      " |                specifying the column to search in.\n",
      " |              - For a DataFrame nested dictionaries, e.g.,\n",
      " |                ``{'a': {'b': np.nan}}``, are read as follows: look in column\n",
      " |                'a' for the value 'b' and replace it with NaN. The `value`\n",
      " |                parameter should be ``None`` to use a nested dict in this\n",
      " |                way. You can nest regular expressions as well. Note that\n",
      " |                column names (the top-level dictionary keys in a nested\n",
      " |                dictionary) **cannot** be regular expressions.\n",
      " |      \n",
      " |          * None:\n",
      " |      \n",
      " |              - This means that the `regex` argument must be a string,\n",
      " |                compiled regular expression, or list, dict, ndarray or\n",
      " |                Series of such elements. If `value` is also ``None`` then\n",
      " |                this **must** be a nested dictionary or Series.\n",
      " |      \n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to replace any values matching `to_replace` with.\n",
      " |          For a DataFrame a dict of values can be used to specify which\n",
      " |          value to use for each column (columns not in the dict will not be\n",
      " |          filled). Regular expressions, strings and lists or dicts of such\n",
      " |          objects are also allowed.\n",
      " |      inplace : boolean, default False\n",
      " |          If True, in place. Note: this will modify any\n",
      " |          other views on this object (e.g. a column from a DataFrame).\n",
      " |          Returns the caller if this is True.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill.\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      " |          string. Alternatively, this could be a regular expression or a\n",
      " |          list, dict, or array of regular expressions in which case\n",
      " |          `to_replace` must be ``None``.\n",
      " |      method : {'pad', 'ffill', 'bfill', `None`}\n",
      " |          The method to use when for replacement, when `to_replace` is a\n",
      " |          scalar, list or tuple and `value` is ``None``.\n",
      " |      \n",
      " |          .. versionchanged:: 0.23.0\n",
      " |              Added to DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.fillna : Fill NA values\n",
      " |      Series.where : Replace values based on boolean condition\n",
      " |      Series.str.replace : Simple string replacement.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Object after replacement.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not\n",
      " |            ``None``.\n",
      " |      TypeError\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |            ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable\n",
      " |            into a regular expression or is a list, dict, ndarray, or\n",
      " |            Series.\n",
      " |          * When replacing multiple ``bool`` or ``datetime64`` objects and\n",
      " |            the arguments to `to_replace` does not match the type of the\n",
      " |            value being replaced\n",
      " |      ValueError\n",
      " |          * If a ``list`` or an ``ndarray`` is passed to `to_replace` and\n",
      " |            `value` but they are not the same length.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |        rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |        cannot provide, for example, a regular expression matching floating\n",
      " |        point numbers and expect the columns in your frame that have a\n",
      " |        numeric dtype to be matched. However, if those floating point\n",
      " |        numbers *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |        and play with this method to gain intuition about how it works.\n",
      " |      * When dict is used as the `to_replace` value, it is like\n",
      " |        key(s) in the dict are the to_replace part and\n",
      " |        value(s) in the dict are the value parameter.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      **Scalar `to_replace` and `value`**\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, 2, 3, 4])\n",
      " |      >>> s.replace(0, 5)\n",
      " |      0    5\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
      " |      ...                    'B': [5, 6, 7, 8, 9],\n",
      " |      ...                    'C': ['a', 'b', 'c', 'd', 'e']})\n",
      " |      >>> df.replace(0, 5)\n",
      " |         A  B  C\n",
      " |      0  5  5  a\n",
      " |      1  1  6  b\n",
      " |      2  2  7  c\n",
      " |      3  3  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      **List-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], 4)\n",
      " |         A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  4  6  b\n",
      " |      2  4  7  c\n",
      " |      3  4  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], [4, 3, 2, 1])\n",
      " |         A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  3  6  b\n",
      " |      2  2  7  c\n",
      " |      3  1  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> s.replace([1, 2], method='bfill')\n",
      " |      0    0\n",
      " |      1    3\n",
      " |      2    3\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **dict-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace({0: 10, 1: 100})\n",
      " |           A  B  C\n",
      " |      0   10  5  a\n",
      " |      1  100  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4    4  9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': 0, 'B': 5}, 100)\n",
      " |           A    B  C\n",
      " |      0  100  100  a\n",
      " |      1    1    6  b\n",
      " |      2    2    7  c\n",
      " |      3    3    8  d\n",
      " |      4    4    9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': {0: 100, 4: 400}})\n",
      " |           A  B  C\n",
      " |      0  100  5  a\n",
      " |      1    1  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4  400  9  e\n",
      " |      \n",
      " |      **Regular expression `to_replace`**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],\n",
      " |      ...                    'B': ['abc', 'bar', 'xyz']})\n",
      " |      >>> df.replace(to_replace=r'^ba.$', value='new', regex=True)\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  bar\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=r'^ba.$', value='new')\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex={r'^ba.$':'new', 'foo':'xyz'})\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   xyz  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=[r'^ba.$', 'foo'], value='new')\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   new  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      Note that when replacing multiple ``bool`` or ``datetime64`` objects,\n",
      " |      the data types in the `to_replace` parameter must match the data\n",
      " |      type of the value being replaced:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [True, False, True],\n",
      " |      ...                    'B': [False, True, False]})\n",
      " |      >>> df.replace({'a string': 'new value', True: False})  # raises\n",
      " |      Traceback (most recent call last):\n",
      " |          ...\n",
      " |      TypeError: Cannot compare types 'ndarray(dtype=bool)' and 'str'\n",
      " |      \n",
      " |      This raises a ``TypeError`` because one of the ``dict`` keys is not of\n",
      " |      the correct type for replacement.\n",
      " |      \n",
      " |      Compare the behavior of ``s.replace({'a': None})`` and\n",
      " |      ``s.replace('a', None)`` to understand the pecularities\n",
      " |      of the `to_replace` parameter:\n",
      " |      \n",
      " |      >>> s = pd.Series([10, 'a', 'a', 'b', 'a'])\n",
      " |      \n",
      " |      When one uses a dict as the `to_replace` value, it is like the\n",
      " |      value(s) in the dict are equal to the `value` parameter.\n",
      " |      ``s.replace({'a': None})`` is equivalent to\n",
      " |      ``s.replace(to_replace={'a': None}, value=None, method=None)``:\n",
      " |      \n",
      " |      >>> s.replace({'a': None})\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |      \n",
      " |      When ``value=None`` and `to_replace` is a scalar, list or\n",
      " |      tuple, `replace` uses the method parameter (default 'pad') to do the\n",
      " |      replacement. So this is why the 'a' values are being replaced by 10\n",
      " |      in rows 1 and 2 and 'b' in row 4 in this case.\n",
      " |      The command ``s.replace('a', None)`` is actually equivalent to\n",
      " |      ``s.replace(to_replace='a', value=None, method='pad')``:\n",
      " |      \n",
      " |      >>> s.replace('a', None)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    10\n",
      " |      3     b\n",
      " |      4     b\n",
      " |      dtype: object\n",
      " |  \n",
      " |  reset_index(self, level=None, drop=False, name=None, inplace=False)\n",
      " |      Generate a new DataFrame or Series with the index reset.\n",
      " |      \n",
      " |      This is useful when the index needs to be treated as a column, or\n",
      " |      when the index is meaningless and needs to be reset to the default\n",
      " |      before another operation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default optional\n",
      " |          For a Series with a MultiIndex, only remove the specified levels\n",
      " |          from the index. Removes all levels by default.\n",
      " |      drop : bool, default False\n",
      " |          Just reset the index, without inserting it as a column in\n",
      " |          the new DataFrame.\n",
      " |      name : object, optional\n",
      " |          The name to use for the column containing the original Series\n",
      " |          values. Uses ``self.name`` by default. This argument is ignored\n",
      " |          when `drop` is True.\n",
      " |      inplace : bool, default False\n",
      " |          Modify the Series in place (do not create a new object).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          When `drop` is False (the default), a DataFrame is returned.\n",
      " |          The newly created columns will come first in the DataFrame,\n",
      " |          followed by the original Series values.\n",
      " |          When `drop` is True, a `Series` is returned.\n",
      " |          In either case, if ``inplace=True``, no value is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.reset_index: Analogous function for DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4], name='foo',\n",
      " |      ...               index=pd.Index(['a', 'b', 'c', 'd'], name='idx'))\n",
      " |      \n",
      " |      Generate a DataFrame with default index.\n",
      " |      \n",
      " |      >>> s.reset_index()\n",
      " |        idx  foo\n",
      " |      0   a    1\n",
      " |      1   b    2\n",
      " |      2   c    3\n",
      " |      3   d    4\n",
      " |      \n",
      " |      To specify the name of the new column use `name`.\n",
      " |      \n",
      " |      >>> s.reset_index(name='values')\n",
      " |        idx  values\n",
      " |      0   a       1\n",
      " |      1   b       2\n",
      " |      2   c       3\n",
      " |      3   d       4\n",
      " |      \n",
      " |      To generate a new Series with the default set `drop` to True.\n",
      " |      \n",
      " |      >>> s.reset_index(drop=True)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      Name: foo, dtype: int64\n",
      " |      \n",
      " |      To update the Series in place, without generating a new one\n",
      " |      set `inplace` to True. Note that it also requires ``drop=True``.\n",
      " |      \n",
      " |      >>> s.reset_index(inplace=True, drop=True)\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      Name: foo, dtype: int64\n",
      " |      \n",
      " |      The `level` parameter is interesting for Series with a multi-level\n",
      " |      index.\n",
      " |      \n",
      " |      >>> arrays = [np.array(['bar', 'bar', 'baz', 'baz']),\n",
      " |      ...           np.array(['one', 'two', 'one', 'two'])]\n",
      " |      >>> s2 = pd.Series(\n",
      " |      ...     range(4), name='foo',\n",
      " |      ...     index=pd.MultiIndex.from_arrays(arrays,\n",
      " |      ...                                     names=['a', 'b']))\n",
      " |      \n",
      " |      To remove a specific level from the Index, use `level`.\n",
      " |      \n",
      " |      >>> s2.reset_index(level='a')\n",
      " |             a  foo\n",
      " |      b\n",
      " |      one  bar    0\n",
      " |      two  bar    1\n",
      " |      one  baz    2\n",
      " |      two  baz    3\n",
      " |      \n",
      " |      If `level` is not set, all levels are removed from the Index.\n",
      " |      \n",
      " |      >>> s2.reset_index()\n",
      " |           a    b  foo\n",
      " |      0  bar  one    0\n",
      " |      1  bar  two    1\n",
      " |      2  baz  one    2\n",
      " |      3  baz  two    3\n",
      " |  \n",
      " |  rfloordiv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Integer division of series and other, element-wise (binary operator `rfloordiv`).\n",
      " |      \n",
      " |      Equivalent to ``other // series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.floordiv\n",
      " |  \n",
      " |  rmod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Modulo of series and other, element-wise (binary operator `rmod`).\n",
      " |      \n",
      " |      Equivalent to ``other % series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.mod\n",
      " |  \n",
      " |  rmul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Multiplication of series and other, element-wise (binary operator `rmul`).\n",
      " |      \n",
      " |      Equivalent to ``other * series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.mul\n",
      " |  \n",
      " |  rolling(self, window, min_periods=None, center=False, win_type=None, on=None, axis=0, closed=None)\n",
      " |      Provides rolling window calculations.\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, or offset\n",
      " |          Size of the moving window. This is the number of observations used for\n",
      " |          calculating the statistic. Each window will be a fixed size.\n",
      " |      \n",
      " |          If its an offset then this will be the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes. This is\n",
      " |          new in 0.19.0\n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA). For a window that is specified by an offset,\n",
      " |          this will default to 1.\n",
      " |      center : boolean, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      win_type : string, default None\n",
      " |          Provide a window type. If ``None``, all points are evenly weighted.\n",
      " |          See the notes below for further information.\n",
      " |      on : string, optional\n",
      " |          For a DataFrame, column on which to calculate\n",
      " |          the rolling window, rather than the index\n",
      " |      closed : string, default None\n",
      " |          Make the interval closed on the 'right', 'left', 'both' or\n",
      " |          'neither' endpoints.\n",
      " |          For offset-based windows, it defaults to 'right'.\n",
      " |          For fixed windows, defaults to 'both'. Remaining cases not implemented\n",
      " |          for fixed windows.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      axis : int or string, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window or Rolling sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the 'triang'\n",
      " |      window type.\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='triang').sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  2.5\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, min_periods defaults\n",
      " |      to the window length.\n",
      " |      \n",
      " |      >>> df.rolling(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Same as above, but explicitly set the min_periods\n",
      " |      \n",
      " |      >>> df.rolling(2, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  2.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      A ragged (meaning not-a-regular frequency), time-indexed DataFrame\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      " |      ...                   index = [pd.Timestamp('20130101 09:00:00'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:02'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:03'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:05'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:06')])\n",
      " |      \n",
      " |      >>> df\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  2.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      \n",
      " |      Contrasting to an integer rolling window, this will roll a variable\n",
      " |      length window corresponding to the time period.\n",
      " |      The default for min_periods is 1.\n",
      " |      \n",
      " |      >>> df.rolling('2s').sum()\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  3.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      To learn more about the offsets & frequency strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      The recognized win_types are:\n",
      " |      \n",
      " |      * ``boxcar``\n",
      " |      * ``triang``\n",
      " |      * ``blackman``\n",
      " |      * ``hamming``\n",
      " |      * ``bartlett``\n",
      " |      * ``parzen``\n",
      " |      * ``bohman``\n",
      " |      * ``blackmanharris``\n",
      " |      * ``nuttall``\n",
      " |      * ``barthann``\n",
      " |      * ``kaiser`` (needs beta)\n",
      " |      * ``gaussian`` (needs std)\n",
      " |      * ``general_gaussian`` (needs power, width)\n",
      " |      * ``slepian`` (needs width).\n",
      " |      \n",
      " |      If ``win_type=None`` all points are evenly weighted. To learn more about\n",
      " |      different window types see `scipy.signal window functions\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/signal.html#window-functions>`__.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      ewm : Provides exponential weighted functions\n",
      " |  \n",
      " |  round(self, decimals=0, *args, **kwargs)\n",
      " |      Round each value in a Series to the given number of decimals.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int\n",
      " |          Number of decimal places to round to (default: 0).\n",
      " |          If decimals is negative, it specifies the number of\n",
      " |          positions to the left of the decimal point.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around\n",
      " |      DataFrame.round\n",
      " |  \n",
      " |  rpow(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Exponential power of series and other, element-wise (binary operator `rpow`).\n",
      " |      \n",
      " |      Equivalent to ``other ** series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.pow\n",
      " |  \n",
      " |  rsub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Subtraction of series and other, element-wise (binary operator `rsub`).\n",
      " |      \n",
      " |      Equivalent to ``other - series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.sub\n",
      " |  \n",
      " |  rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.truediv\n",
      " |  \n",
      " |  searchsorted(self, value, side='left', sorter=None)\n",
      " |      Find indices where elements should be inserted to maintain order.\n",
      " |      \n",
      " |      Find the indices into a sorted Series `self` such that, if the\n",
      " |      corresponding elements in `value` were inserted before the indices,\n",
      " |      the order of `self` would be preserved.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : array_like\n",
      " |          Values to insert into `self`.\n",
      " |      side : {'left', 'right'}, optional\n",
      " |          If 'left', the index of the first suitable location found is given.\n",
      " |          If 'right', return the last such index.  If there is no suitable\n",
      " |          index, return either 0 or N (where N is the length of `self`).\n",
      " |      sorter : 1-D array_like, optional\n",
      " |          Optional array of integer indices that sort `self` into ascending\n",
      " |          order. They are typically the result of ``np.argsort``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indices : array of ints\n",
      " |          Array of insertion points with the same shape as `value`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.searchsorted\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Binary search is used to find the required insertion points.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> x = pd.Series([1, 2, 3])\n",
      " |      >>> x\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> x.searchsorted(4)\n",
      " |      array([3])\n",
      " |      \n",
      " |      >>> x.searchsorted([0, 4])\n",
      " |      array([0, 3])\n",
      " |      \n",
      " |      >>> x.searchsorted([1, 3], side='left')\n",
      " |      array([0, 2])\n",
      " |      \n",
      " |      >>> x.searchsorted([1, 3], side='right')\n",
      " |      array([1, 3])\n",
      " |      \n",
      " |      >>> x = pd.Categorical(['apple', 'bread', 'bread',\n",
      " |                              'cheese', 'milk'], ordered=True)\n",
      " |      [apple, bread, bread, cheese, milk]\n",
      " |      Categories (4, object): [apple < bread < cheese < milk]\n",
      " |      \n",
      " |      >>> x.searchsorted('bread')\n",
      " |      array([1])     # Note: an array, not a scalar\n",
      " |      \n",
      " |      >>> x.searchsorted(['bread'], side='right')\n",
      " |      array([3])\n",
      " |  \n",
      " |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sem : scalar or Series (if level specified)\n",
      " |  \n",
      " |  set_value(self, label, value, takeable=False)\n",
      " |      Quickly set single value at passed label. If label is not contained,\n",
      " |      a new object is created with the label placed at the end of the result\n",
      " |      index.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Please use .at[] or .iat[] accessors.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      label : object\n",
      " |          Partial indexing with MultiIndex not allowed\n",
      " |      value : object\n",
      " |          Scalar value\n",
      " |      takeable : interpret the index as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      series : Series\n",
      " |          If label is contained, will be reference to calling Series,\n",
      " |          otherwise a new object\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift index by desired number of periods with an optional time freq\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, optional\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM').\n",
      " |          See Notes.\n",
      " |      axis : {0 or 'index'}\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is specified then the index values are shifted but the data\n",
      " |      is not realigned. That is, use freq if you would like to extend the\n",
      " |      index when shifting and preserve the original data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : Series\n",
      " |  \n",
      " |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased skew over requested axis\n",
      " |      Normalized by N-1\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      skew : scalar or Series (if level specified)\n",
      " |  \n",
      " |  sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True)\n",
      " |      Sort Series by index labels.\n",
      " |      \n",
      " |      Returns a new Series sorted by label if `inplace` argument is\n",
      " |      ``False``, otherwise updates the original series and returns None.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int, default 0\n",
      " |          Axis to direct sorting. This can only be 0 for Series.\n",
      " |      level : int, optional\n",
      " |          If not None, sort on values in specified index level(s).\n",
      " |      ascending : bool, default true\n",
      " |          Sort ascending vs. descending.\n",
      " |      inplace : bool, default False\n",
      " |          If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information.  'mergesort' is the only stable algorithm. For\n",
      " |          DataFrames, this option is only applied when sorting on a single\n",
      " |          column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |          If 'first' puts NaNs at the beginning, 'last' puts NaNs at the end.\n",
      " |          Not implemented for MultiIndex.\n",
      " |      sort_remaining : bool, default True\n",
      " |          If true and sorting by level and index is multilevel, sort by other\n",
      " |          levels too (in order) after sorting by specified level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The original Series sorted by the labels\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sort_index: Sort DataFrame by the index\n",
      " |      DataFrame.sort_values: Sort DataFrame by the value\n",
      " |      Series.sort_values : Sort Series by the value\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, 4])\n",
      " |      >>> s.sort_index()\n",
      " |      1    c\n",
      " |      2    b\n",
      " |      3    a\n",
      " |      4    d\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Sort Descending\n",
      " |      \n",
      " |      >>> s.sort_index(ascending=False)\n",
      " |      4    d\n",
      " |      3    a\n",
      " |      2    b\n",
      " |      1    c\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Sort Inplace\n",
      " |      \n",
      " |      >>> s.sort_index(inplace=True)\n",
      " |      >>> s\n",
      " |      1    c\n",
      " |      2    b\n",
      " |      3    a\n",
      " |      4    d\n",
      " |      dtype: object\n",
      " |      \n",
      " |      By default NaNs are put at the end, but use `na_position` to place\n",
      " |      them at the beginning\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, np.nan])\n",
      " |      >>> s.sort_index(na_position='first')\n",
      " |      NaN     d\n",
      " |       1.0    c\n",
      " |       2.0    b\n",
      " |       3.0    a\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Specify index level to sort\n",
      " |      \n",
      " |      >>> arrays = [np.array(['qux', 'qux', 'foo', 'foo',\n",
      " |      ...                     'baz', 'baz', 'bar', 'bar']),\n",
      " |      ...           np.array(['two', 'one', 'two', 'one',\n",
      " |      ...                     'two', 'one', 'two', 'one'])]\n",
      " |      >>> s = pd.Series([1, 2, 3, 4, 5, 6, 7, 8], index=arrays)\n",
      " |      >>> s.sort_index(level=1)\n",
      " |      bar  one    8\n",
      " |      baz  one    6\n",
      " |      foo  one    4\n",
      " |      qux  one    2\n",
      " |      bar  two    7\n",
      " |      baz  two    5\n",
      " |      foo  two    3\n",
      " |      qux  two    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Does not sort by remaining levels when sorting by levels\n",
      " |      \n",
      " |      >>> s.sort_index(level=1, sort_remaining=False)\n",
      " |      qux  one    2\n",
      " |      foo  one    4\n",
      " |      baz  one    6\n",
      " |      bar  one    8\n",
      " |      qux  two    1\n",
      " |      foo  two    3\n",
      " |      baz  two    5\n",
      " |      bar  two    7\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  sort_values(self, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
      " |      Sort by the values.\n",
      " |      \n",
      " |      Sort a Series in ascending or descending order by some\n",
      " |      criterion.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'}, default 0\n",
      " |          Axis to direct sorting. The value 'index' is accepted for\n",
      " |          compatibility with DataFrame.sort_values.\n",
      " |      ascending : bool, default True\n",
      " |          If True, sort values in ascending order, otherwise descending.\n",
      " |      inplace : bool, default False\n",
      " |          If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort' or 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information. 'mergesort' is the only stable  algorithm.\n",
      " |      na_position : {'first' or 'last'}, default 'last'\n",
      " |          Argument 'first' puts NaNs at the beginning, 'last' puts NaNs at\n",
      " |          the end.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series ordered by values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index : Sort by the Series indices.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values along either axis.\n",
      " |      DataFrame.sort_index : Sort DataFrame by indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([np.nan, 1, 3, 10, 5])\n",
      " |      >>> s\n",
      " |      0     NaN\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      3     10.0\n",
      " |      4     5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values ascending order (default behaviour)\n",
      " |      \n",
      " |      >>> s.sort_values(ascending=True)\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      4     5.0\n",
      " |      3    10.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values descending order\n",
      " |      \n",
      " |      >>> s.sort_values(ascending=False)\n",
      " |      3    10.0\n",
      " |      4     5.0\n",
      " |      2     3.0\n",
      " |      1     1.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values inplace\n",
      " |      \n",
      " |      >>> s.sort_values(ascending=False, inplace=True)\n",
      " |      >>> s\n",
      " |      3    10.0\n",
      " |      4     5.0\n",
      " |      2     3.0\n",
      " |      1     1.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values putting NAs first\n",
      " |      \n",
      " |      >>> s.sort_values(na_position='first')\n",
      " |      0     NaN\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      4     5.0\n",
      " |      3    10.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort a series of strings\n",
      " |      \n",
      " |      >>> s = pd.Series(['z', 'b', 'd', 'a', 'c'])\n",
      " |      >>> s\n",
      " |      0    z\n",
      " |      1    b\n",
      " |      2    d\n",
      " |      3    a\n",
      " |      4    c\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s.sort_values()\n",
      " |      3    a\n",
      " |      1    b\n",
      " |      4    c\n",
      " |      2    d\n",
      " |      0    z\n",
      " |      dtype: object\n",
      " |  \n",
      " |  sortlevel(self, level=0, ascending=True, sort_remaining=True)\n",
      " |      Sort Series with MultiIndex by chosen level. Data will be\n",
      " |      lexicographically sorted by the chosen level followed by the other\n",
      " |      levels (in order),\n",
      " |      \n",
      " |      .. deprecated:: 0.20.0\n",
      " |          Use :meth:`Series.sort_index`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int or level name, default None\n",
      " |      ascending : bool, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index(level=...)\n",
      " |  \n",
      " |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      std : scalar or Series (if level specified)\n",
      " |  \n",
      " |  sub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Subtraction of series and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rsub\n",
      " |  \n",
      " |  subtract = sub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Subtraction of series and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rsub\n",
      " |  \n",
      " |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the sum of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |          .. versionadded :: 0.22.0\n",
      " |      \n",
      " |             Added with the default being 0. This means the sum of an all-NA\n",
      " |             or empty Series is 0, and the product of an all-NA or empty\n",
      " |             Series is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sum : scalar or Series (if level specified)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      " |      \n",
      " |      >>> pd.Series([]).sum()  # min_count=0 is the default\n",
      " |      0.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      " |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      " |      \n",
      " |      >>> pd.Series([]).sum(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum()\n",
      " |      0.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  swaplevel(self, i=-2, j=-1, copy=True)\n",
      " |      Swap levels i and j in a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int, string (can be mixed)\n",
      " |          Level of index to be swapped. Can pass level name as string.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      swapped : Series\n",
      " |      \n",
      " |      .. versionchanged:: 0.18.1\n",
      " |      \n",
      " |         The indexes ``i`` and ``j`` are now optional, and default to\n",
      " |         the two innermost levels of the index.\n",
      " |  \n",
      " |  to_csv(self, path=None, index=True, sep=',', na_rep='', float_format=None, header=False, index_label=None, mode='w', encoding=None, compression=None, date_format=None, decimal='.')\n",
      " |      Write Series to a comma-separated values (csv) file\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string or file handle, default None\n",
      " |          File path or object, if None is provided the result is returned as\n",
      " |          a string.\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      header : boolean, default False\n",
      " |          Write out series name\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      mode : Python write mode, default 'w'\n",
      " |      sep : character, default \",\"\n",
      " |          Field delimiter for the output file.\n",
      " |      encoding : string, optional\n",
      " |          a string representing the encoding to use if the contents are\n",
      " |          non-ascii, for python versions prior to 3\n",
      " |      compression : string, optional\n",
      " |          A string representing the compression to use in the output file.\n",
      " |          Allowed values are 'gzip', 'bz2', 'zip', 'xz'. This input is only\n",
      " |          used when the first argument is a filename.\n",
      " |      date_format: string, default None\n",
      " |          Format string for datetime objects.\n",
      " |      decimal: string, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data\n",
      " |  \n",
      " |  to_dict(self, into=<class 'dict'>)\n",
      " |      Convert Series to {label -> value} dict or dict-like object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      into : class, default dict\n",
      " |          The collections.Mapping subclass to use as the return\n",
      " |          object. Can be the actual class or an empty\n",
      " |          instance of the mapping type you want.  If you want a\n",
      " |          collections.defaultdict, you must pass it initialized.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value_dict : collections.Mapping\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.to_dict()\n",
      " |      {0: 1, 1: 2, 2: 3, 3: 4}\n",
      " |      >>> from collections import OrderedDict, defaultdict\n",
      " |      >>> s.to_dict(OrderedDict)\n",
      " |      OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n",
      " |      >>> dd = defaultdict(list)\n",
      " |      >>> s.to_dict(dd)\n",
      " |      defaultdict(<type 'list'>, {0: 1, 1: 2, 2: 3, 3: 4})\n",
      " |  \n",
      " |  to_excel(self, excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True)\n",
      " |      Write Series to an excel sheet\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : string or ExcelWriter object\n",
      " |          File path or existing ExcelWriter\n",
      " |      sheet_name : string, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write\n",
      " |      header : boolean or list of string, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow :\n",
      " |          upper left cell row to dump data frame\n",
      " |      startcol :\n",
      " |          upper left cell column to dump data frame\n",
      " |      engine : string, default None\n",
      " |          write engine to use - you can also set this via the options\n",
      " |          ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |      merge_cells : boolean, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      encoding: string, default None\n",
      " |          encoding of the resulting excel file. Only necessary for xlwt,\n",
      " |          other writers support unicode natively.\n",
      " |      inf_rep : string, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel)\n",
      " |      freeze_panes : tuple of integer (length 2), default None\n",
      " |          Specifies the one-based bottommost row and rightmost column that\n",
      " |          is to be frozen\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If passing an existing ExcelWriter object, then the sheet will be added\n",
      " |      to the existing workbook.  This can be used to save different\n",
      " |      DataFrames to one workbook:\n",
      " |      \n",
      " |      >>> writer = pd.ExcelWriter('output.xlsx')\n",
      " |      >>> df1.to_excel(writer,'Sheet1')\n",
      " |      >>> df2.to_excel(writer,'Sheet2')\n",
      " |      >>> writer.save()\n",
      " |      \n",
      " |      For compatibility with to_csv, to_excel serializes lists and dicts to\n",
      " |      strings before writing.\n",
      " |  \n",
      " |  to_frame(self, name=None)\n",
      " |      Convert Series to DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object, default None\n",
      " |          The passed name should substitute for the series name (if it has\n",
      " |          one).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      data_frame : DataFrame\n",
      " |  \n",
      " |  to_period(self, freq=None, copy=True)\n",
      " |      Convert Series from DatetimeIndex to PeriodIndex with desired\n",
      " |      frequency (inferred from index if not passed)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ts : Series with PeriodIndex\n",
      " |  \n",
      " |  to_sparse(self, kind='block', fill_value=None)\n",
      " |      Convert Series to SparseSeries\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      kind : {'block', 'integer'}\n",
      " |      fill_value : float, defaults to NaN (missing)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sp : SparseSeries\n",
      " |  \n",
      " |  to_string(self, buf=None, na_rep='NaN', float_format=None, header=True, index=True, length=False, dtype=False, name=False, max_rows=None)\n",
      " |      Render a string representation of the Series\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : StringIO-like, optional\n",
      " |          buffer to write to\n",
      " |      na_rep : string, optional\n",
      " |          string representation of NAN to use, default 'NaN'\n",
      " |      float_format : one-parameter function, optional\n",
      " |          formatter function to apply to columns' elements if they are floats\n",
      " |          default None\n",
      " |      header: boolean, default True\n",
      " |          Add the Series header (index name)\n",
      " |      index : bool, optional\n",
      " |          Add index (row) labels, default True\n",
      " |      length : boolean, default False\n",
      " |          Add the Series length\n",
      " |      dtype : boolean, default False\n",
      " |          Add the Series dtype\n",
      " |      name : boolean, default False\n",
      " |          Add the Series name if not None\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to show before truncating. If None, show\n",
      " |          all.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      formatted : string (if not buffer passed)\n",
      " |  \n",
      " |  to_timestamp(self, freq=None, how='start', copy=True)\n",
      " |      Cast to datetimeindex of timestamps, at *beginning* of period\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default frequency of PeriodIndex\n",
      " |          Desired frequency\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ts : Series with DatetimeIndex\n",
      " |  \n",
      " |  transform(self, func, *args, **kwargs)\n",
      " |      Call function producing a like-indexed NDFrame\n",
      " |      and return a NDFrame with the transformed values\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable, string, dictionary, or list of string/callables\n",
      " |          To apply to column\n",
      " |      \n",
      " |          Accepted Combinations are:\n",
      " |      \n",
      " |          - string function name\n",
      " |          - function\n",
      " |          - list of functions\n",
      " |          - dict of column names -> functions (or list of functions)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      transformed : NDFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n",
      " |      ...                   index=pd.date_range('1/1/2000', periods=10))\n",
      " |      df.iloc[3:7] = np.nan\n",
      " |      \n",
      " |      >>> df.transform(lambda x: (x - x.mean()) / x.std())\n",
      " |                         A         B         C\n",
      " |      2000-01-01  0.579457  1.236184  0.123424\n",
      " |      2000-01-02  0.370357 -0.605875 -1.231325\n",
      " |      2000-01-03  1.455756 -0.277446  0.288967\n",
      " |      2000-01-04       NaN       NaN       NaN\n",
      " |      2000-01-05       NaN       NaN       NaN\n",
      " |      2000-01-06       NaN       NaN       NaN\n",
      " |      2000-01-07       NaN       NaN       NaN\n",
      " |      2000-01-08 -0.498658  1.274522  1.642524\n",
      " |      2000-01-09 -0.540524 -1.012676 -0.828968\n",
      " |      2000-01-10 -1.366388 -0.614710  0.005378\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.NDFrame.aggregate\n",
      " |      pandas.NDFrame.apply\n",
      " |  \n",
      " |  truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rtruediv\n",
      " |  \n",
      " |  unique(self)\n",
      " |      Return unique values of Series object.\n",
      " |      \n",
      " |      Uniques are returned in order of appearance. Hash table-based unique,\n",
      " |      therefore does NOT sort.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray or Categorical\n",
      " |          The unique values returned as a NumPy array. In case of categorical\n",
      " |          data type, returned as a Categorical.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.unique : top-level unique method for any 1-d array-like object.\n",
      " |      Index.unique : return Index with unique values from an Index object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([2, 1, 3, 3], name='A').unique()\n",
      " |      array([2, 1, 3])\n",
      " |      \n",
      " |      >>> pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)]).unique()\n",
      " |      array(['2016-01-01T00:00:00.000000000'], dtype='datetime64[ns]')\n",
      " |      \n",
      " |      >>> pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern')\n",
      " |      ...            for _ in range(3)]).unique()\n",
      " |      array([Timestamp('2016-01-01 00:00:00-0500', tz='US/Eastern')],\n",
      " |            dtype=object)\n",
      " |      \n",
      " |      An unordered Categorical will return categories in the order of\n",
      " |      appearance.\n",
      " |      \n",
      " |      >>> pd.Series(pd.Categorical(list('baabc'))).unique()\n",
      " |      [b, a, c]\n",
      " |      Categories (3, object): [b, a, c]\n",
      " |      \n",
      " |      An ordered Categorical preserves the category ordering.\n",
      " |      \n",
      " |      >>> pd.Series(pd.Categorical(list('baabc'), categories=list('abc'),\n",
      " |      ...                          ordered=True)).unique()\n",
      " |      [b, a, c]\n",
      " |      Categories (3, object): [a < b < c]\n",
      " |  \n",
      " |  unstack(self, level=-1, fill_value=None)\n",
      " |      Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.\n",
      " |      The level involved will automatically get sorted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, string, or list of these, default last level\n",
      " |          Level(s) to unstack, can pass level name\n",
      " |      fill_value : replace NaN with this value if the unstack produces\n",
      " |          missing values\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4],\n",
      " |      ...     index=pd.MultiIndex.from_product([['one', 'two'], ['a', 'b']]))\n",
      " |      >>> s\n",
      " |      one  a    1\n",
      " |           b    2\n",
      " |      two  a    3\n",
      " |           b    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a  b\n",
      " |      one  1  2\n",
      " |      two  3  4\n",
      " |      \n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a    1    3\n",
      " |      b    2    4\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      unstacked : DataFrame\n",
      " |  \n",
      " |  update(self, other)\n",
      " |      Modify Series in place using non-NA values from passed\n",
      " |      Series. Aligns on index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, 5, 6]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'b', 'c'])\n",
      " |      >>> s.update(pd.Series(['d', 'e'], index=[0, 2]))\n",
      " |      >>> s\n",
      " |      0    d\n",
      " |      1    b\n",
      " |      2    e\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, 5, 6, 7, 8]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      If ``other`` contains NaNs the corresponding values are not updated\n",
      " |      in the original Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, np.nan, 6]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    2\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  valid(self, inplace=False, **kwargs)\n",
      " |      Return Series without null values.\n",
      " |      \n",
      " |      .. deprecated:: 0.23.0\n",
      " |          Use :meth:`Series.dropna` instead.\n",
      " |  \n",
      " |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      var : scalar or Series (if level specified)\n",
      " |  \n",
      " |  view(self, dtype=None)\n",
      " |      Create a new view of the Series.\n",
      " |      \n",
      " |      This function will return a new Series with a view of the same\n",
      " |      underlying values in memory, optionally reinterpreted with a new data\n",
      " |      type. The new data type must preserve the same size in bytes as to not\n",
      " |      cause index misalignment.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type\n",
      " |          Data type object or one of their string representations.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          A new Series object as a view of the same data in memory.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.view : Equivalent numpy function to create a new view of\n",
      " |          the same data in memory.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Series are instantiated with ``dtype=float64`` by default. While\n",
      " |      ``numpy.ndarray.view()`` will return a view with the same data type as\n",
      " |      the original array, ``Series.view()`` (without specified dtype)\n",
      " |      will try using ``float64`` and may fail if the original data type size\n",
      " |      in bytes is not the same.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([-2, -1, 0, 1, 2], dtype='int8')\n",
      " |      >>> s\n",
      " |      0   -2\n",
      " |      1   -1\n",
      " |      2    0\n",
      " |      3    1\n",
      " |      4    2\n",
      " |      dtype: int8\n",
      " |      \n",
      " |      The 8 bit signed integer representation of `-1` is `0b11111111`, but\n",
      " |      the same bytes represent 255 if read as an 8 bit unsigned integer:\n",
      " |      \n",
      " |      >>> us = s.view('uint8')\n",
      " |      >>> us\n",
      " |      0    254\n",
      " |      1    255\n",
      " |      2      0\n",
      " |      3      1\n",
      " |      4      2\n",
      " |      dtype: uint8\n",
      " |      \n",
      " |      The views share the same underlying values:\n",
      " |      \n",
      " |      >>> us[0] = 128\n",
      " |      >>> s\n",
      " |      0   -128\n",
      " |      1     -1\n",
      " |      2      0\n",
      " |      3      1\n",
      " |      4      2\n",
      " |      dtype: int8\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pandas.core.series.Series:\n",
      " |  \n",
      " |  from_array(arr, index=None, name=None, dtype=None, copy=False, fastpath=False) from builtins.type\n",
      " |      Construct Series from array.\n",
      " |      \n",
      " |      .. deprecated :: 0.23.0\n",
      " |          Use pd.Series(..) constructor instead.\n",
      " |  \n",
      " |  from_csv(path, sep=',', parse_dates=True, header=None, index_col=0, encoding=None, infer_datetime_format=False) from builtins.type\n",
      " |      Read CSV file.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use :func:`pandas.read_csv` instead.\n",
      " |      \n",
      " |      It is preferable to use the more powerful :func:`pandas.read_csv`\n",
      " |      for most general purposes, but ``from_csv`` makes for an easy\n",
      " |      roundtrip to and from a file (the exact counterpart of\n",
      " |      ``to_csv``), especially with a time Series.\n",
      " |      \n",
      " |      This method only differs from :func:`pandas.read_csv` in some defaults:\n",
      " |      \n",
      " |      - `index_col` is ``0`` instead of ``None`` (take first column as index\n",
      " |        by default)\n",
      " |      - `header` is ``None`` instead of ``0`` (the first row is not used as\n",
      " |        the column names)\n",
      " |      - `parse_dates` is ``True`` instead of ``False`` (try parsing the index\n",
      " |        as datetime by default)\n",
      " |      \n",
      " |      With :func:`pandas.read_csv`, the option ``squeeze=True`` can be used\n",
      " |      to return a Series like ``from_csv``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string file path or file handle / StringIO\n",
      " |      sep : string, default ','\n",
      " |          Field delimiter\n",
      " |      parse_dates : boolean, default True\n",
      " |          Parse dates. Different default from read_table\n",
      " |      header : int, default None\n",
      " |          Row to use as header (skip prior rows)\n",
      " |      index_col : int or sequence, default 0\n",
      " |          Column to use for index. If a sequence is given, a MultiIndex\n",
      " |          is used. Different default from read_table\n",
      " |      encoding : string, optional\n",
      " |          a string representing the encoding to use if the contents are\n",
      " |          non-ascii, for python versions prior to 3\n",
      " |      infer_datetime_format: boolean, default False\n",
      " |          If True and `parse_dates` is True for a column, try to infer the\n",
      " |          datetime format based on the first datetime string. If the format\n",
      " |          can be inferred, there often will be a large parsing speed-up.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.read_csv\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.series.Series:\n",
      " |  \n",
      " |  asobject\n",
      " |      Return object Series which contains boxed values.\n",
      " |      \n",
      " |      .. deprecated :: 0.23.0\n",
      " |      \n",
      " |         Use ``astype(object)`` instead.\n",
      " |      \n",
      " |      *this is an internal non-public method*\n",
      " |  \n",
      " |  axes\n",
      " |      Return a list of the row axis labels\n",
      " |  \n",
      " |  dtype\n",
      " |      return the dtype object of the underlying data\n",
      " |  \n",
      " |  dtypes\n",
      " |      return the dtype object of the underlying data\n",
      " |  \n",
      " |  ftype\n",
      " |      return if the data is sparse|dense\n",
      " |  \n",
      " |  ftypes\n",
      " |      return if the data is sparse|dense\n",
      " |  \n",
      " |  imag\n",
      " |  \n",
      " |  index\n",
      " |      The index (axis labels) of the Series.\n",
      " |  \n",
      " |  name\n",
      " |  \n",
      " |  real\n",
      " |  \n",
      " |  values\n",
      " |      Return Series as ndarray or ndarray-like\n",
      " |      depending on the dtype\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      arr : numpy.ndarray or ndarray-like\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([1, 2, 3]).values\n",
      " |      array([1, 2, 3])\n",
      " |      \n",
      " |      >>> pd.Series(list('aabc')).values\n",
      " |      array(['a', 'a', 'b', 'c'], dtype=object)\n",
      " |      \n",
      " |      >>> pd.Series(list('aabc')).astype('category').values\n",
      " |      [a, a, b, c]\n",
      " |      Categories (3, object): [a, b, c]\n",
      " |      \n",
      " |      Timezone aware datetime data is converted to UTC:\n",
      " |      \n",
      " |      >>> pd.Series(pd.date_range('20130101', periods=3,\n",
      " |      ...                         tz='US/Eastern')).values\n",
      " |      array(['2013-01-01T05:00:00.000000000',\n",
      " |             '2013-01-02T05:00:00.000000000',\n",
      " |             '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.series.Series:\n",
      " |  \n",
      " |  cat = <class 'pandas.core.arrays.categorical.CategoricalAccessor'>\n",
      " |      Accessor object for categorical properties of the Series values.\n",
      " |      \n",
      " |      Be aware that assigning to `categories` is a inplace operation, while all\n",
      " |      methods return new categorical data per default (but can be called with\n",
      " |      `inplace=True`).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or CategoricalIndex\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.cat.categories\n",
      " |      >>> s.cat.categories = list('abc')\n",
      " |      >>> s.cat.rename_categories(list('cab'))\n",
      " |      >>> s.cat.reorder_categories(list('cab'))\n",
      " |      >>> s.cat.add_categories(['d','e'])\n",
      " |      >>> s.cat.remove_categories(['d'])\n",
      " |      >>> s.cat.remove_unused_categories()\n",
      " |      >>> s.cat.set_categories(list('abcde'))\n",
      " |      >>> s.cat.as_ordered()\n",
      " |      >>> s.cat.as_unordered()\n",
      " |  \n",
      " |  plot = <class 'pandas.plotting._core.SeriesPlotMethods'>\n",
      " |      Series plotting accessor and method\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.plot.line()\n",
      " |      >>> s.plot.bar()\n",
      " |      >>> s.plot.hist()\n",
      " |      \n",
      " |      Plotting methods can also be accessed by calling the accessor as a method\n",
      " |      with the ``kind`` argument:\n",
      " |      ``s.plot(kind='line')`` is equivalent to ``s.plot.line()``\n",
      " |  \n",
      " |  str = <class 'pandas.core.strings.StringMethods'>\n",
      " |      Vectorized string functions for Series and Index. NAs stay NA unless\n",
      " |      handled otherwise by a particular method. Patterned after Python's string\n",
      " |      methods, with some inspiration from R's stringr package.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.str.split('_')\n",
      " |      >>> s.str.replace('_', '')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return an iterator of the values.\n",
      " |      \n",
      " |      These are each a scalar type, which is a Python scalar\n",
      " |      (for str, int, float) or a pandas scalar\n",
      " |      (for Timestamp/Timedelta/Interval/Period)\n",
      " |  \n",
      " |  factorize(self, sort=False, na_sentinel=-1)\n",
      " |      Encode the object as an enumerated type or categorical variable.\n",
      " |      \n",
      " |      This method is useful for obtaining a numeric representation of an\n",
      " |      array when all that matters is identifying distinct values. `factorize`\n",
      " |      is available as both a top-level function :func:`pandas.factorize`,\n",
      " |      and as a method :meth:`Series.factorize` and :meth:`Index.factorize`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sort : boolean, default False\n",
      " |          Sort `uniques` and shuffle `labels` to maintain the\n",
      " |          relationship.\n",
      " |      \n",
      " |      na_sentinel : int, default -1\n",
      " |          Value to mark \"not found\".\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : ndarray\n",
      " |          An integer ndarray that's an indexer into `uniques`.\n",
      " |          ``uniques.take(labels)`` will have the same values as `values`.\n",
      " |      uniques : ndarray, Index, or Categorical\n",
      " |          The unique valid values. When `values` is Categorical, `uniques`\n",
      " |          is a Categorical. When `values` is some other pandas object, an\n",
      " |          `Index` is returned. Otherwise, a 1-D ndarray is returned.\n",
      " |      \n",
      " |          .. note ::\n",
      " |      \n",
      " |             Even if there's a missing value in `values`, `uniques` will\n",
      " |             *not* contain an entry for it.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.cut : Discretize continuous-valued array.\n",
      " |      pandas.unique : Find the unique valuse in an array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      These examples all show factorize as a top-level method like\n",
      " |      ``pd.factorize(values)``. The results are identical for methods like\n",
      " |      :meth:`Series.factorize`.\n",
      " |      \n",
      " |      >>> labels, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'])\n",
      " |      >>> labels\n",
      " |      array([0, 0, 1, 2, 0])\n",
      " |      >>> uniques\n",
      " |      array(['b', 'a', 'c'], dtype=object)\n",
      " |      \n",
      " |      With ``sort=True``, the `uniques` will be sorted, and `labels` will be\n",
      " |      shuffled so that the relationship is the maintained.\n",
      " |      \n",
      " |      >>> labels, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'], sort=True)\n",
      " |      >>> labels\n",
      " |      array([1, 1, 0, 2, 1])\n",
      " |      >>> uniques\n",
      " |      array(['a', 'b', 'c'], dtype=object)\n",
      " |      \n",
      " |      Missing values are indicated in `labels` with `na_sentinel`\n",
      " |      (``-1`` by default). Note that missing values are never\n",
      " |      included in `uniques`.\n",
      " |      \n",
      " |      >>> labels, uniques = pd.factorize(['b', None, 'a', 'c', 'b'])\n",
      " |      >>> labels\n",
      " |      array([ 0, -1,  1,  2,  0])\n",
      " |      >>> uniques\n",
      " |      array(['b', 'a', 'c'], dtype=object)\n",
      " |      \n",
      " |      Thus far, we've only factorized lists (which are internally coerced to\n",
      " |      NumPy arrays). When factorizing pandas objects, the type of `uniques`\n",
      " |      will differ. For Categoricals, a `Categorical` is returned.\n",
      " |      \n",
      " |      >>> cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])\n",
      " |      >>> labels, uniques = pd.factorize(cat)\n",
      " |      >>> labels\n",
      " |      array([0, 0, 1])\n",
      " |      >>> uniques\n",
      " |      [a, c]\n",
      " |      Categories (3, object): [a, b, c]\n",
      " |      \n",
      " |      Notice that ``'b'`` is in ``uniques.categories``, desipite not being\n",
      " |      present in ``cat.values``.\n",
      " |      \n",
      " |      For all other pandas objects, an Index of the appropriate type is\n",
      " |      returned.\n",
      " |      \n",
      " |      >>> cat = pd.Series(['a', 'a', 'c'])\n",
      " |      >>> labels, uniques = pd.factorize(cat)\n",
      " |      >>> labels\n",
      " |      array([0, 0, 1])\n",
      " |      >>> uniques\n",
      " |      Index(['a', 'c'], dtype='object')\n",
      " |  \n",
      " |  item(self)\n",
      " |      return the first element of the underlying data as a python\n",
      " |      scalar\n",
      " |  \n",
      " |  nunique(self, dropna=True)\n",
      " |      Return number of unique elements in the object.\n",
      " |      \n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include NaN in the count.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nunique : int\n",
      " |  \n",
      " |  tolist(self)\n",
      " |      Return a list of the values.\n",
      " |      \n",
      " |      These are each a scalar type, which is a Python scalar\n",
      " |      (for str, int, float) or a pandas scalar\n",
      " |      (for Timestamp/Timedelta/Interval/Period)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.tolist\n",
      " |  \n",
      " |  transpose(self, *args, **kwargs)\n",
      " |      return the transpose, which is by definition self\n",
      " |  \n",
      " |  value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
      " |      Returns object containing counts of unique values.\n",
      " |      \n",
      " |      The resulting object will be in descending order so that the\n",
      " |      first element is the most frequently-occurring element.\n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      normalize : boolean, default False\n",
      " |          If True then the object returned will contain the relative\n",
      " |          frequencies of the unique values.\n",
      " |      sort : boolean, default True\n",
      " |          Sort by values\n",
      " |      ascending : boolean, default False\n",
      " |          Sort in ascending order\n",
      " |      bins : integer, optional\n",
      " |          Rather than count values, group them into half-open bins,\n",
      " |          a convenience for pd.cut, only works with numeric data\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include counts of NaN.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      counts : Series\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  base\n",
      " |      return the base object if the memory of the underlying data is\n",
      " |      shared\n",
      " |  \n",
      " |  data\n",
      " |      return the data pointer of the underlying data\n",
      " |  \n",
      " |  empty\n",
      " |  \n",
      " |  flags\n",
      " |      return the ndarray.flags for the underlying data\n",
      " |  \n",
      " |  hasnans\n",
      " |      return if I have any nans; enables various perf speedups\n",
      " |  \n",
      " |  is_monotonic\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_increasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic : boolean\n",
      " |  \n",
      " |  is_monotonic_decreasing\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_decreasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic_decreasing : boolean\n",
      " |  \n",
      " |  is_monotonic_increasing\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_increasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic : boolean\n",
      " |  \n",
      " |  is_unique\n",
      " |      Return boolean if values in the object are unique\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_unique : boolean\n",
      " |  \n",
      " |  itemsize\n",
      " |      return the size of the dtype of the item of the underlying data\n",
      " |  \n",
      " |  nbytes\n",
      " |      return the number of bytes in the underlying data\n",
      " |  \n",
      " |  ndim\n",
      " |      return the number of dimensions of the underlying data,\n",
      " |      by definition 1\n",
      " |  \n",
      " |  shape\n",
      " |      return a tuple of the shape of the underlying data\n",
      " |  \n",
      " |  size\n",
      " |      return the number of elements in the underlying data\n",
      " |  \n",
      " |  strides\n",
      " |      return the strides of the underlying data\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __array_priority__ = 1000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __abs__(self)\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self)\n",
      " |  \n",
      " |  __contains__(self, key)\n",
      " |      True if the key is in the info axis\n",
      " |  \n",
      " |  __deepcopy__(self, memo=None)\n",
      " |  \n",
      " |  __delitem__(self, key)\n",
      " |      Delete item\n",
      " |  \n",
      " |  __finalize__(self, other, method=None, **kwargs)\n",
      " |      Propagate metadata from other to self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : optional, a passed method name ; possibly to take different\n",
      " |          types of propagation actions based on this\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __invert__(self)\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __pos__(self)\n",
      " |  \n",
      " |  __round__(self, decimals=0)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  abs(self)\n",
      " |      Return a Series/DataFrame with absolute numeric value of each element.\n",
      " |      \n",
      " |      This function only applies to elements that are all numeric.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs\n",
      " |          Series/DataFrame containing the absolute value of each element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For ``complex`` inputs, ``1.2 + 1j``, the absolute value is\n",
      " |      :math:`\\sqrt{ a^2 + b^2 }`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Absolute numeric values in a Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([-1.10, 2, -3.33, 4])\n",
      " |      >>> s.abs()\n",
      " |      0    1.10\n",
      " |      1    2.00\n",
      " |      2    3.33\n",
      " |      3    4.00\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with complex numbers.\n",
      " |      \n",
      " |      >>> s = pd.Series([1.2 + 1j])\n",
      " |      >>> s.abs()\n",
      " |      0    1.56205\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with a Timedelta element.\n",
      " |      \n",
      " |      >>> s = pd.Series([pd.Timedelta('1 days')])\n",
      " |      >>> s.abs()\n",
      " |      0   1 days\n",
      " |      dtype: timedelta64[ns]\n",
      " |      \n",
      " |      Select rows with data closest to certain value using argsort (from\n",
      " |      `StackOverflow <https://stackoverflow.com/a/17758115>`__).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'a': [4, 5, 6, 7],\n",
      " |      ...     'b': [10, 20, 30, 40],\n",
      " |      ...     'c': [100, 50, -30, -50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |           a    b    c\n",
      " |      0    4   10  100\n",
      " |      1    5   20   50\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      >>> df.loc[(df.c - 43).abs().argsort()]\n",
      " |           a    b    c\n",
      " |      1    5   20   50\n",
      " |      0    4   10  100\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.absolute : calculate the absolute value element-wise.\n",
      " |  \n",
      " |  add_prefix(self, prefix)\n",
      " |      Prefix labels with string `prefix`.\n",
      " |      \n",
      " |      For Series, the row labels are prefixed.\n",
      " |      For DataFrame, the column labels are prefixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : str\n",
      " |          The string to add before each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_suffix: Suffix row labels with string `suffix`.\n",
      " |      DataFrame.add_suffix: Suffix column labels with string `suffix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_prefix('item_')\n",
      " |      item_0    1\n",
      " |      item_1    2\n",
      " |      item_2    3\n",
      " |      item_3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4],  'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_prefix('col_')\n",
      " |           col_A  col_B\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  add_suffix(self, suffix)\n",
      " |      Suffix labels with string `suffix`.\n",
      " |      \n",
      " |      For Series, the row labels are suffixed.\n",
      " |      For DataFrame, the column labels are suffixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : str\n",
      " |          The string to add after each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_prefix: Prefix row labels with string `prefix`.\n",
      " |      DataFrame.add_prefix: Prefix column labels with string `prefix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_suffix('_item')\n",
      " |      0_item    1\n",
      " |      1_item    2\n",
      " |      2_item    3\n",
      " |      3_item    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4],  'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_suffix('_col')\n",
      " |           A_col  B_col\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  as_blocks(self, copy=True)\n",
      " |      Convert the frame to a dict of dtype -> Constructor Types that each has\n",
      " |      a homogeneous dtype.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in\n",
      " |            as_matrix)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : boolean, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : a dict of dtype -> Constructor Types\n",
      " |  \n",
      " |  as_matrix(self, columns=None)\n",
      " |      Convert the frame to its Numpy-array representation.\n",
      " |      \n",
      " |      .. deprecated:: 0.23.0\n",
      " |          Use :meth:`DataFrame.values` instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      columns: list, optional, default:None\n",
      " |          If None, return all columns, otherwise, returns specified columns.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : ndarray\n",
      " |          If the caller is heterogeneous and contains booleans or objects,\n",
      " |          the result will be of dtype=object. See Notes.\n",
      " |      \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Return is NOT a Numpy-matrix, rather, a Numpy-array.\n",
      " |      \n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcase to\n",
      " |      int32. By numpy.find_common_type convention, mixing int64 and uint64\n",
      " |      will result in a flot64 dtype.\n",
      " |      \n",
      " |      This method is provided for backwards compatibility. Generally,\n",
      " |      it is recommended to use '.values'.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.values\n",
      " |  \n",
      " |  asfreq(self, freq, method=None, how=None, normalize=False, fill_value=None)\n",
      " |      Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Optionally provide filling method to pad/backfill missing values.\n",
      " |      \n",
      " |      Returns the original data conformed to a new index with the specified\n",
      " |      frequency. ``resample`` is more appropriate if an operation, such as\n",
      " |      summarization, is necessary to represent the data at the new frequency.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset object, or string\n",
      " |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      " |          Method to use for filling holes in reindexed Series (note this\n",
      " |          does not fill NaNs that already were present):\n",
      " |      \n",
      " |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * 'backfill' / 'bfill': use NEXT valid observation to fill\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only, see PeriodIndex.asfreq\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight\n",
      " |      fill_value: scalar, optional\n",
      " |          Value to use for missing values, applied during upsampling (note\n",
      " |          this does not fill NaNs that already were present).\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 4 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      " |      >>> df = pd.DataFrame({'s':series})\n",
      " |      >>> df\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    NaN\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``fill value``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    9.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    9.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    9.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``method``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', method='bfill')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    2.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    3.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the frequency strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |  \n",
      " |  asof(self, where, subset=None)\n",
      " |      The last row without any NaN is taken (or the last row without\n",
      " |      NaN considering only the subset of columns in the case of a DataFrame)\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0 For DataFrame\n",
      " |      \n",
      " |      If there is no good value, NaN is returned for a Series\n",
      " |      a Series of NaN values for a DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array of dates\n",
      " |      subset : string or list of strings, default None\n",
      " |         if not None use these columns for NaN propagation\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted\n",
      " |      Raises if this is not the case\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      where is scalar\n",
      " |      \n",
      " |        - value or NaN if input is Series\n",
      " |        - Series if input is DataFrame\n",
      " |      \n",
      " |      where is Index: same shape object as input\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_asof\n",
      " |  \n",
      " |  astype(self, dtype, copy=True, errors='raise', **kwargs)\n",
      " |      Cast a pandas object to a specified dtype ``dtype``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type, or dict of column name -> data type\n",
      " |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      " |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      " |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      " |          or more of the DataFrame's columns to column-specific types.\n",
      " |      copy : bool, default True.\n",
      " |          Return a copy when ``copy=True`` (be very careful setting\n",
      " |          ``copy=False`` as changes to values then may propagate to other\n",
      " |          pandas objects).\n",
      " |      errors : {'raise', 'ignore'}, default 'raise'.\n",
      " |          Control raising of exceptions on invalid data for provided dtype.\n",
      " |      \n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      raise_on_error : raise on invalid input\n",
      " |          .. deprecated:: 0.20.0\n",
      " |             Use ``errors`` instead\n",
      " |      kwargs : keyword arguments to pass on to the constructor\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      casted : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int32\n",
      " |      >>> ser.astype('int64')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Convert to categorical type:\n",
      " |      \n",
      " |      >>> ser.astype('category')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [1, 2]\n",
      " |      \n",
      " |      Convert to ordered categorical type with custom ordering:\n",
      " |      \n",
      " |      >>> ser.astype('category', ordered=True, categories=[2, 1])\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [2 < 1]\n",
      " |      \n",
      " |      Note that using ``copy=False`` and changing data on a new\n",
      " |      pandas object may propagate changes:\n",
      " |      \n",
      " |      >>> s1 = pd.Series([1,2])\n",
      " |      >>> s2 = s1.astype('int64', copy=False)\n",
      " |      >>> s2[0] = 10\n",
      " |      >>> s1  # note that s1[0] has changed too\n",
      " |      0    10\n",
      " |      1     2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Convert argument to a numeric type.\n",
      " |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      " |  \n",
      " |  at_time(self, time, asof=False)\n",
      " |      Select values at particular time of day (e.g. 9:30AM).\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_at_time : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='12H')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 00:00:00  3\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      >>> ts.at_time('12:00')\n",
      " |                           A\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      between_time : Select values between particular times of the day\n",
      " |      first : Select initial periods of time series based on a date offset\n",
      " |      last : Select final periods of time series based on a date offset\n",
      " |      DatetimeIndex.indexer_at_time : Get just the index locations for\n",
      " |          values at particular time of the day\n",
      " |  \n",
      " |  between_time(self, start_time, end_time, include_start=True, include_end=True)\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |      \n",
      " |      By setting ``start_time`` to be later than ``end_time``,\n",
      " |      you can get the times that are *not* between the two times.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or string\n",
      " |      end_time : datetime.time or string\n",
      " |      include_start : boolean, default True\n",
      " |      include_end : boolean, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_between_time : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      >>> ts.between_time('0:15', '0:45')\n",
      " |                           A\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      \n",
      " |      You get the times that are *not* between two times by setting\n",
      " |      ``start_time`` later than ``end_time``:\n",
      " |      \n",
      " |      >>> ts.between_time('0:45', '0:15')\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      at_time : Select values at a particular time of the day\n",
      " |      first : Select initial periods of time series based on a date offset\n",
      " |      last : Select final periods of time series based on a date offset\n",
      " |      DatetimeIndex.indexer_between_time : Get just the index locations for\n",
      " |          values between particular times of the day\n",
      " |  \n",
      " |  bfill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for :meth:`DataFrame.fillna(method='bfill') <DataFrame.fillna>`\n",
      " |  \n",
      " |  bool(self)\n",
      " |      Return the bool of a single element PandasObject.\n",
      " |      \n",
      " |      This must be a boolean scalar value, either True or False.  Raise a\n",
      " |      ValueError if the PandasObject does not have exactly 1 element, or that\n",
      " |      element is not boolean\n",
      " |  \n",
      " |  clip(self, lower=None, upper=None, axis=None, inplace=False, *args, **kwargs)\n",
      " |      Trim values at input threshold(s).\n",
      " |      \n",
      " |      Assigns values outside boundary to boundary values. Thresholds\n",
      " |      can be singular values or array like, and in the latter case\n",
      " |      the clipping is performed element-wise in the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array_like, default None\n",
      " |          Minimum threshold value. All values below this\n",
      " |          threshold will be set to it.\n",
      " |      upper : float or array_like, default None\n",
      " |          Maximum threshold value. All values above this\n",
      " |          threshold will be set to it.\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted\n",
      " |          for compatibility with numpy.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      clip_lower : Clip values below specified threshold(s).\n",
      " |      clip_upper : Clip values above specified threshold(s).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as calling object with the values outside the\n",
      " |          clip boundaries replaced\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df\n",
      " |         col_0  col_1\n",
      " |      0      9     -2\n",
      " |      1     -3     -7\n",
      " |      2      0      6\n",
      " |      3     -1      8\n",
      " |      4      5     -5\n",
      " |      \n",
      " |      Clips per column using lower and upper thresholds:\n",
      " |      \n",
      " |      >>> df.clip(-4, 6)\n",
      " |         col_0  col_1\n",
      " |      0      6     -2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3     -1      6\n",
      " |      4      5     -4\n",
      " |      \n",
      " |      Clips using specific lower and upper thresholds per column element:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, -1, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2\n",
      " |      1   -4\n",
      " |      2   -1\n",
      " |      3    6\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.clip(t, t + 4, axis=0)\n",
      " |         col_0  col_1\n",
      " |      0      6      2\n",
      " |      1     -3     -4\n",
      " |      2      0      3\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |  \n",
      " |  clip_lower(self, threshold, axis=None, inplace=False)\n",
      " |      Return copy of the input with values below a threshold truncated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      threshold : numeric or array-like\n",
      " |          Minimum value allowed. All values below threshold will be set to\n",
      " |          this value.\n",
      " |      \n",
      " |          * float : every value is compared to `threshold`.\n",
      " |          * array-like : The shape of `threshold` should match the object\n",
      " |            it's compared to. When `self` is a Series, `threshold` should be\n",
      " |            the length. When `self` is a DataFrame, `threshold` should 2-D\n",
      " |            and the same shape as `self` for ``axis=None``, or 1-D and the\n",
      " |            same length as the axis being compared.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Align `self` with `threshold` along the given axis.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.clip : Return copy of input with values below and above\n",
      " |          thresholds truncated.\n",
      " |      Series.clip_upper : Return copy of input with values above\n",
      " |          threshold truncated.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Series single threshold clipping:\n",
      " |      \n",
      " |      >>> s = pd.Series([5, 6, 7, 8, 9])\n",
      " |      >>> s.clip_lower(8)\n",
      " |      0    8\n",
      " |      1    8\n",
      " |      2    8\n",
      " |      3    8\n",
      " |      4    9\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Series clipping element-wise using an array of thresholds. `threshold`\n",
      " |      should be the same length as the Series.\n",
      " |      \n",
      " |      >>> elemwise_thresholds = [4, 8, 7, 2, 5]\n",
      " |      >>> s.clip_lower(elemwise_thresholds)\n",
      " |      0    5\n",
      " |      1    8\n",
      " |      2    7\n",
      " |      3    8\n",
      " |      4    9\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      DataFrames can be compared to a scalar.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 3, 5], \"B\": [2, 4, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      \n",
      " |      >>> df.clip_lower(3)\n",
      " |         A  B\n",
      " |      0  3  3\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      \n",
      " |      Or to an array of values. By default, `threshold` should be the same\n",
      " |      shape as the DataFrame.\n",
      " |      \n",
      " |      >>> df.clip_lower(np.array([[3, 4], [2, 2], [6, 2]]))\n",
      " |         A  B\n",
      " |      0  3  4\n",
      " |      1  3  4\n",
      " |      2  6  6\n",
      " |      \n",
      " |      Control how `threshold` is broadcast with `axis`. In this case\n",
      " |      `threshold` should be the same length as the axis specified by\n",
      " |      `axis`.\n",
      " |      \n",
      " |      >>> df.clip_lower(np.array([3, 3, 5]), axis='index')\n",
      " |         A  B\n",
      " |      0  3  3\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      \n",
      " |      >>> df.clip_lower(np.array([4, 5]), axis='columns')\n",
      " |         A  B\n",
      " |      0  4  5\n",
      " |      1  4  5\n",
      " |      2  5  6\n",
      " |  \n",
      " |  clip_upper(self, threshold, axis=None, inplace=False)\n",
      " |      Return copy of input with values above given value(s) truncated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      threshold : float or array_like\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with threshold along the given axis.\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      clip\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |  \n",
      " |  consolidate(self, inplace=False)\n",
      " |      Compute NDFrame with \"consolidated\" internals (data of each dtype\n",
      " |      grouped together in a single ndarray).\n",
      " |      \n",
      " |      .. deprecated:: 0.20.0\n",
      " |          Consolidate will be an internal implementation only.\n",
      " |  \n",
      " |  convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)\n",
      " |      Attempt to infer better dtype for object columns.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      convert_dates : boolean, default True\n",
      " |          If True, convert to date where possible. If 'coerce', force\n",
      " |          conversion, with unconvertible values becoming NaT.\n",
      " |      convert_numeric : boolean, default False\n",
      " |          If True, attempt to coerce to numbers (including strings), with\n",
      " |          unconvertible values becoming NaN.\n",
      " |      convert_timedeltas : boolean, default True\n",
      " |          If True, convert to timedelta where possible. If 'coerce', force\n",
      " |          conversion, with unconvertible values becoming NaT.\n",
      " |      copy : boolean, default True\n",
      " |          If True, return a copy even if no copy is necessary (e.g. no\n",
      " |          conversion was done). Note: This is meant for internal use, and\n",
      " |          should not be confused with inplace.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Return a fixed frequency timedelta index,\n",
      " |          with day as the default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same as input object\n",
      " |  \n",
      " |  describe(self, percentiles=None, include=None, exclude=None)\n",
      " |      Generates descriptive statistics that summarize the central tendency,\n",
      " |      dispersion and shape of a dataset's distribution, excluding\n",
      " |      ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      summary:  Series/DataFrame of summary statistics\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                       3\n",
      " |      unique                      2\n",
      " |      top       2010-01-01 00:00:00\n",
      " |      freq                        2\n",
      " |      first     2000-01-01 00:00:00\n",
      " |      last      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({ 'object': ['a', 'b', 'c'],\n",
      " |      ...                     'numeric': [1, 2, 3],\n",
      " |      ...                     'categorical': pd.Categorical(['d','e','f'])\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')\n",
      " |              categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      c\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.object])\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         c\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              f\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      c\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.object])\n",
      " |              categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count\n",
      " |      DataFrame.max\n",
      " |      DataFrame.min\n",
      " |      DataFrame.mean\n",
      " |      DataFrame.std\n",
      " |      DataFrame.select_dtypes\n",
      " |  \n",
      " |  equals(self, other)\n",
      " |      Determines if two NDFrame objects contain the same elements. NaNs in\n",
      " |      the same location are considered equal.\n",
      " |  \n",
      " |  ffill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`\n",
      " |  \n",
      " |  filter(self, items=None, like=None, regex=None, axis=None)\n",
      " |      Subset rows or columns of dataframe according to labels in\n",
      " |      the specified index.\n",
      " |      \n",
      " |      Note that this routine does not filter a dataframe on its\n",
      " |      contents. The filter is applied to the labels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          List of info axis to restrict to (must not all be present)\n",
      " |      like : string\n",
      " |          Keep info axis where \"arg in col == True\"\n",
      " |      regex : string (regular expression)\n",
      " |          Keep info axis with re.search(regex, col) == True\n",
      " |      axis : int or string axis name\n",
      " |          The axis to filter on.  By default this is the info axis,\n",
      " |          'index' for Series, 'columns' for DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |      one  two  three\n",
      " |      mouse     1    2      3\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      >>> # select columns by name\n",
      " |      >>> df.filter(items=['one', 'three'])\n",
      " |      one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select columns by regular expression\n",
      " |      >>> df.filter(regex='e$', axis=1)\n",
      " |      one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select rows containing 'bbi'\n",
      " |      >>> df.filter(like='bbi', axis=0)\n",
      " |      one  two  three\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.loc\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The ``items``, ``like``, and ``regex`` parameters are\n",
      " |      enforced to be mutually exclusive.\n",
      " |      \n",
      " |      ``axis`` defaults to the info axis that is used when indexing\n",
      " |      with ``[]``.\n",
      " |  \n",
      " |  first(self, offset)\n",
      " |      Convenience method for subsetting initial periods of time series data\n",
      " |      based on a date offset.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the first 3 days:\n",
      " |      \n",
      " |      >>> ts.first('3D')\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      \n",
      " |      Notice the data for 3 first calender days were returned, not the first\n",
      " |      3 days observed in the dataset, and therefore data for 2018-04-13 was\n",
      " |      not returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      last : Select final periods of time series based on a date offset\n",
      " |      at_time : Select values at a particular time of the day\n",
      " |      between_time : Select values between particular times of the day\n",
      " |  \n",
      " |  first_valid_index(self)\n",
      " |      Return index for first non-NA/null value.\n",
      " |      \n",
      " |      Notes\n",
      " |      --------\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty NDFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      --------\n",
      " |      scalar : type of index\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (DataFrame column, Panel slice,\n",
      " |      etc.). Returns default value if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : type of items contained in object\n",
      " |  \n",
      " |  get_dtype_counts(self)\n",
      " |      Return counts of unique dtypes in this object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dtype : Series\n",
      " |          Series with the count of columns with each dtype.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dtypes : Return the dtypes in this object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = [['a', 1, 1.0], ['b', 2, 2.0], ['c', 3, 3.0]]\n",
      " |      >>> df = pd.DataFrame(a, columns=['str', 'int', 'float'])\n",
      " |      >>> df\n",
      " |        str  int  float\n",
      " |      0   a    1    1.0\n",
      " |      1   b    2    2.0\n",
      " |      2   c    3    3.0\n",
      " |      \n",
      " |      >>> df.get_dtype_counts()\n",
      " |      float64    1\n",
      " |      int64      1\n",
      " |      object     1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  get_ftype_counts(self)\n",
      " |      Return counts of unique ftypes in this object.\n",
      " |      \n",
      " |      .. deprecated:: 0.23.0\n",
      " |      \n",
      " |      This is useful for SparseDataFrame or for DataFrames containing\n",
      " |      sparse arrays.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dtype : Series\n",
      " |          Series with the count of columns with each type and\n",
      " |          sparsity (dense/sparse)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ftypes : Return ftypes (indication of sparse/dense and dtype) in\n",
      " |          this object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = [['a', 1, 1.0], ['b', 2, 2.0], ['c', 3, 3.0]]\n",
      " |      >>> df = pd.DataFrame(a, columns=['str', 'int', 'float'])\n",
      " |      >>> df\n",
      " |        str  int  float\n",
      " |      0   a    1    1.0\n",
      " |      1   b    2    2.0\n",
      " |      2   c    3    3.0\n",
      " |      \n",
      " |      >>> df.get_ftype_counts()\n",
      " |      float64:dense    1\n",
      " |      int64:dense      1\n",
      " |      object:dense     1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)\n",
      " |      Group series using mapper (dict or key function, apply given function\n",
      " |      to group, return result as series) or by a series of columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping, function, label, or list of labels\n",
      " |          Used to determine the groups for the groupby.\n",
      " |          If ``by`` is a function, it's called on each value of the object's\n",
      " |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      " |          will be used to determine the groups (the Series' values are first\n",
      " |          aligned; see ``.align()`` method). If an ndarray is passed, the\n",
      " |          values are used as-is determine the groups. A label or list of\n",
      " |          labels may be passed to group by the columns in ``self``. Notice\n",
      " |          that a tuple is interpreted a (single) key.\n",
      " |      axis : int, default 0\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels\n",
      " |      as_index : boolean, default True\n",
      " |          For aggregated output, return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output\n",
      " |      sort : boolean, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each\n",
      " |          group.  groupby preserves the order of rows within each group.\n",
      " |      group_keys : boolean, default True\n",
      " |          When calling apply, add group keys to index to identify pieces\n",
      " |      squeeze : boolean, default False\n",
      " |          reduce the dimensionality of the return type if possible,\n",
      " |          otherwise return a consistent type\n",
      " |      observed : boolean, default False\n",
      " |          This only applies if any of the groupers are Categoricals\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      GroupBy object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      DataFrame results\n",
      " |      \n",
      " |      >>> data.groupby(func, axis=0).mean()\n",
      " |      >>> data.groupby(['col1', 'col2'])['col3'].mean()\n",
      " |      \n",
      " |      DataFrame with hierarchical index\n",
      " |      \n",
      " |      >>> data.groupby(['col1', 'col2']).mean()\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/groupby.html>`_ for more.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      resample : Convenience method for frequency conversion and resampling\n",
      " |          of time series.\n",
      " |  \n",
      " |  head(self, n=5)\n",
      " |      Return the first `n` rows.\n",
      " |      \n",
      " |      This function returns the first `n` rows for the object based\n",
      " |      on position. It is useful for quickly testing if your object\n",
      " |      has the right type of data in it.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      obj_head : type of caller\n",
      " |          The first `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.tail: Returns the last `n` rows.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal':['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the first 5 lines\n",
      " |      \n",
      " |      >>> df.head()\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      \n",
      " |      Viewing the first `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.head(3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |  \n",
      " |  infer_objects(self)\n",
      " |      Attempt to infer better dtypes for object columns.\n",
      " |      \n",
      " |      Attempts soft conversion of object-dtyped\n",
      " |      columns, leaving non-object and unconvertible\n",
      " |      columns unchanged. The inference rules are the\n",
      " |      same as during normal Series/DataFrame construction.\n",
      " |      \n",
      " |      .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Convert argument to numeric typeR\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same type as input object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      " |      >>> df = df.iloc[1:]\n",
      " |      >>> df\n",
      " |         A\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      A    object\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> df.infer_objects().dtypes\n",
      " |      A    int64\n",
      " |      dtype: object\n",
      " |  \n",
      " |  interpolate(self, method='linear', axis=0, limit=None, inplace=False, limit_direction='forward', limit_area=None, downcast=None, **kwargs)\n",
      " |      Interpolate values according to different methods.\n",
      " |      \n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrames/Series with a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'linear', 'time', 'index', 'values', 'nearest', 'zero',\n",
      " |                'slinear', 'quadratic', 'cubic', 'barycentric', 'krogh',\n",
      " |                'polynomial', 'spline', 'piecewise_polynomial',\n",
      " |                'from_derivatives', 'pchip', 'akima'}\n",
      " |      \n",
      " |          * 'linear': ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |            default\n",
      " |          * 'time': interpolation works on daily and higher resolution\n",
      " |            data to interpolate given length of interval\n",
      " |          * 'index', 'values': use the actual numerical values of the index\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      " |            'barycentric', 'polynomial' is passed to\n",
      " |            ``scipy.interpolate.interp1d``. Both 'polynomial' and 'spline'\n",
      " |            require that you also specify an `order` (int),\n",
      " |            e.g. df.interpolate(method='polynomial', order=4).\n",
      " |            These use the actual numerical values of the index.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |            are all wrappers around the scipy interpolation methods of\n",
      " |            similar names. These use the actual numerical values of the\n",
      " |            index. For more information on their behavior, see the\n",
      " |            `scipy documentation\n",
      " |            <http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      " |            and `tutorial documentation\n",
      " |            <http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__\n",
      " |          * 'from_derivatives' refers to BPoly.from_derivatives which\n",
      " |            replaces 'piecewise_polynomial' interpolation method in\n",
      " |            scipy 0.18\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |      \n",
      " |             Added support for the 'akima' method\n",
      " |             Added interpolate method 'from_derivatives' which replaces\n",
      " |             'piecewise_polynomial' in scipy 0.18; backwards-compatible with\n",
      " |             scipy < 0.18\n",
      " |      \n",
      " |      axis : {0, 1}, default 0\n",
      " |          * 0: fill column-by-column\n",
      " |          * 1: fill row-by-row\n",
      " |      limit : int, default None.\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than 0.\n",
      " |      limit_direction : {'forward', 'backward', 'both'}, default 'forward'\n",
      " |      limit_area : {'inside', 'outside'}, default None\n",
      " |          * None: (default) no fill restriction\n",
      " |          * 'inside' Only fill NaNs surrounded by valid values (interpolate).\n",
      " |          * 'outside' Only fill NaNs outside valid values (extrapolate).\n",
      " |      \n",
      " |          If limit is specified, consecutive NaNs will be filled in this\n",
      " |          direction.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      inplace : bool, default False\n",
      " |          Update the NDFrame in place if possible.\n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |      kwargs : keyword arguments to pass on to the interpolating function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame of same shape interpolated at the NaNs\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex, replace, fillna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Filling in NaNs\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s.interpolate()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  last(self, offset)\n",
      " |      Convenience method for subsetting final periods of time series data\n",
      " |      based on a date offset.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the last 3 days:\n",
      " |      \n",
      " |      >>> ts.last('3D')\n",
      " |                  A\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Notice the data for 3 last calender days were returned, not the last\n",
      " |      3 observed days in the dataset, and therefore data for 2018-04-11 was\n",
      " |      not returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      first : Select initial periods of time series based on a date offset\n",
      " |      at_time : Select values at a particular time of the day\n",
      " |      between_time : Select values between particular times of the day\n",
      " |  \n",
      " |  last_valid_index(self)\n",
      " |      Return index for last non-NA/null value.\n",
      " |      \n",
      " |      Notes\n",
      " |      --------\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty NDFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      --------\n",
      " |      scalar : type of index\n",
      " |  \n",
      " |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where `cond` is False and otherwise are from\n",
      " |      `other`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame, array-like, or callable\n",
      " |          Where `cond` is False, keep the original value. Where\n",
      " |          True, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the NDFrame and\n",
      " |          should return boolean NDFrame or array. The callable must\n",
      " |          not change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as cond.\n",
      " |      \n",
      " |      other : scalar, NDFrame, or callable\n",
      " |          Entries where `cond` is True are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the NDFrame and\n",
      " |          should return scalar or NDFrame. The callable must not\n",
      " |          change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as other.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mask method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``mask`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10.0\n",
      " |      1    10.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.where`\n",
      " |  \n",
      " |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, **kwargs)\n",
      " |      Percentage change between the current and a prior element.\n",
      " |      \n",
      " |      Computes the percentage change from the immediately previous row by\n",
      " |      default. This is useful in comparing the percentage of change in a time\n",
      " |      series of elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change.\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs before computing percent changes.\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping.\n",
      " |      freq : DateOffset, timedelta, or offset alias string, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay()).\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments are passed into\n",
      " |          `DataFrame.shift` or `Series.shift`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : Series or DataFrame\n",
      " |          The same type as the calling object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff : Compute the difference of two elements in a Series.\n",
      " |      DataFrame.diff : Compute the difference of two elements in a DataFrame.\n",
      " |      Series.shift : Shift the index by some number of periods.\n",
      " |      DataFrame.shift : Shift the index by some number of periods.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, 85])\n",
      " |      >>> s\n",
      " |      0    90\n",
      " |      1    91\n",
      " |      2    85\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.pct_change()\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(periods=2)\n",
      " |      0         NaN\n",
      " |      1         NaN\n",
      " |      2   -0.055556\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See the percentage change in a Series where filling NAs with last\n",
      " |      valid observation forward to next valid.\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, None, 85])\n",
      " |      >>> s\n",
      " |      0    90.0\n",
      " |      1    91.0\n",
      " |      2     NaN\n",
      " |      3    85.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(fill_method='ffill')\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2    0.000000\n",
      " |      3   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Percentage change in French franc, Deutsche Mark, and Italian lira from\n",
      " |      1980-01-01 to 1980-03-01.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'FR': [4.0405, 4.0963, 4.3149],\n",
      " |      ...     'GR': [1.7246, 1.7482, 1.8519],\n",
      " |      ...     'IT': [804.74, 810.01, 860.13]},\n",
      " |      ...     index=['1980-01-01', '1980-02-01', '1980-03-01'])\n",
      " |      >>> df\n",
      " |                      FR      GR      IT\n",
      " |      1980-01-01  4.0405  1.7246  804.74\n",
      " |      1980-02-01  4.0963  1.7482  810.01\n",
      " |      1980-03-01  4.3149  1.8519  860.13\n",
      " |      \n",
      " |      >>> df.pct_change()\n",
      " |                        FR        GR        IT\n",
      " |      1980-01-01       NaN       NaN       NaN\n",
      " |      1980-02-01  0.013810  0.013684  0.006549\n",
      " |      1980-03-01  0.053365  0.059318  0.061876\n",
      " |      \n",
      " |      Percentage of change in GOOG and APPL stock volume. Shows computing\n",
      " |      the percentage change between columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     '2016': [1769950, 30586265],\n",
      " |      ...     '2015': [1500923, 40912316],\n",
      " |      ...     '2014': [1371819, 41403351]},\n",
      " |      ...     index=['GOOG', 'APPL'])\n",
      " |      >>> df\n",
      " |                2016      2015      2014\n",
      " |      GOOG   1769950   1500923   1371819\n",
      " |      APPL  30586265  40912316  41403351\n",
      " |      \n",
      " |      >>> df.pct_change(axis='columns')\n",
      " |            2016      2015      2014\n",
      " |      GOOG   NaN -0.151997 -0.086016\n",
      " |      APPL   NaN  0.337604  0.012002\n",
      " |  \n",
      " |  pipe(self, func, *args, **kwargs)\n",
      " |      Apply func(self, \\*args, \\*\\*kwargs)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          function to apply to the NDFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the NDFrame.\n",
      " |      args : iterable, optional\n",
      " |          positional arguments passed into ``func``.\n",
      " |      kwargs : mapping, optional\n",
      " |          a dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of ``func``.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      Series, DataFrames or GroupBy objects. Instead of writing\n",
      " |      \n",
      " |      >>> f(g(h(df), arg1=a), arg2=b, arg3=c)\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(f, arg2=b, arg3=c)\n",
      " |      ... )\n",
      " |      \n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe((f, 'arg2'), arg1=a, arg3=c)\n",
      " |      ...  )\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.apply\n",
      " |      pandas.DataFrame.applymap\n",
      " |      pandas.Series.map\n",
      " |  \n",
      " |  pop(self, item)\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      item : str\n",
      " |          Column label to be popped\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      popped : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      " |      ...                    ('parrot', 'bird',     24.0),\n",
      " |      ...                    ('lion',   'mammal',   80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=('name', 'class', 'max_speed'))\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      >>> df.pop('class')\n",
      " |      0      bird\n",
      " |      1      bird\n",
      " |      2    mammal\n",
      " |      3    mammal\n",
      " |      Name: class, dtype: object\n",
      " |      \n",
      " |      >>> df\n",
      " |           name  max_speed\n",
      " |      0  falcon      389.0\n",
      " |      1  parrot       24.0\n",
      " |      2    lion       80.5\n",
      " |      3  monkey        NaN\n",
      " |  \n",
      " |  rank(self, axis=0, method='average', numeric_only=None, na_option='keep', ascending=True, pct=False)\n",
      " |      Compute numerical data ranks (1 through n) along axis. Equal values are\n",
      " |      assigned a rank that is the average of the ranks of those values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          index to direct ranking\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}\n",
      " |          * average: average rank of group\n",
      " |          * min: lowest rank in group\n",
      " |          * max: highest rank in group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. Valid only for DataFrame or\n",
      " |          Panel objects\n",
      " |      na_option : {'keep', 'top', 'bottom'}\n",
      " |          * keep: leave NA values where they are\n",
      " |          * top: smallest rank if ascending\n",
      " |          * bottom: smallest rank if descending\n",
      " |      ascending : boolean, default True\n",
      " |          False for ranks by high (1) to low (N)\n",
      " |      pct : boolean, default False\n",
      " |          Computes percentage rank of data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ranks : same type as caller\n",
      " |  \n",
      " |  reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)\n",
      " |      Return an object with matching indices to myself.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object\n",
      " |      method : string or None\n",
      " |      copy : boolean, default True\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between labels of the other object and this\n",
      " |          object for inexact matches. Can be list-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Like calling s.reindex(index=other.index, columns=other.columns,\n",
      " |                             method=...)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : same as input\n",
      " |  \n",
      " |  rename_axis(self, mapper, axis=0, copy=True, inplace=False)\n",
      " |      Alter the name of the index or columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : scalar, list-like, optional\n",
      " |          Value to set as the axis name attribute.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis.\n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data.\n",
      " |      inplace : boolean, default False\n",
      " |          Modifies the object directly, instead of creating a new Series\n",
      " |          or DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Series, DataFrame, or None\n",
      " |          The same type as the caller or None if `inplace` is True.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Prior to version 0.21.0, ``rename_axis`` could also be used to change\n",
      " |      the axis *labels* by passing a mapping or scalar. This behavior is\n",
      " |      deprecated and will be removed in a future version. Use ``rename``\n",
      " |      instead.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.rename : Alter Series index labels or name\n",
      " |      pandas.DataFrame.rename : Alter DataFrame index labels or name\n",
      " |      pandas.Index.rename : Set new names on index\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.rename_axis(\"foo\")\n",
      " |      foo\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename_axis(\"foo\")\n",
      " |           A  B\n",
      " |      foo\n",
      " |      0    1  4\n",
      " |      1    2  5\n",
      " |      2    3  6\n",
      " |      \n",
      " |      >>> df.rename_axis(\"bar\", axis=\"columns\")\n",
      " |      bar  A  B\n",
      " |      0    1  4\n",
      " |      1    2  5\n",
      " |      2    3  6\n",
      " |  \n",
      " |  resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention='start', kind=None, loffset=None, limit=None, base=0, on=None, level=None)\n",
      " |      Convenience method for frequency conversion and resampling of time\n",
      " |      series.  Object must have a datetime-like index (DatetimeIndex,\n",
      " |      PeriodIndex, or TimedeltaIndex), or pass datetime-like values\n",
      " |      to the on or level keyword.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : string\n",
      " |          the offset string or object representing target conversion\n",
      " |      axis : int, optional, default 0\n",
      " |      closed : {'right', 'left'}\n",
      " |          Which side of bin interval is closed. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      label : {'right', 'left'}\n",
      " |          Which bin edge label to label bucket with. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      convention : {'start', 'end', 's', 'e'}\n",
      " |          For PeriodIndex only, controls whether to use the start or end of\n",
      " |          `rule`\n",
      " |      kind: {'timestamp', 'period'}, optional\n",
      " |          Pass 'timestamp' to convert the resulting index to a\n",
      " |          ``DateTimeIndex`` or 'period' to convert it to a ``PeriodIndex``.\n",
      " |          By default the input representation is retained.\n",
      " |      loffset : timedelta\n",
      " |          Adjust the resampled time labels\n",
      " |      base : int, default 0\n",
      " |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      " |          aggregated intervals. For example, for '5min' frequency, base could\n",
      " |          range from 0 through 4. Defaults to 0\n",
      " |      on : string, optional\n",
      " |          For a DataFrame, column to use instead of index for resampling.\n",
      " |          Column must be datetime-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      level : string or int, optional\n",
      " |          For a MultiIndex, level (name or number) to use for\n",
      " |          resampling.  Level must be datetime-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Resampler object\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#resampling>`_\n",
      " |      for more.\n",
      " |      \n",
      " |      To learn more about the offset strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> series.resample('3T').sum()\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |      To include this value close the right side of the bin interval as\n",
      " |      illustrated in the example below this one.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right').sum()\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> series.resample('30S').asfreq()[0:5] #select first 5 rows\n",
      " |      2000-01-01 00:00:00   0.0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00   1.0\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00   2.0\n",
      " |      Freq: 30S, dtype: float64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``pad`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').pad()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').bfill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Pass a custom function via ``apply``\n",
      " |      \n",
      " |      >>> def custom_resampler(array_like):\n",
      " |      ...     return np.sum(array_like)+5\n",
      " |      \n",
      " |      >>> series.resample('3T').apply(custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      For a Series with a PeriodIndex, the keyword `convention` can be\n",
      " |      used to control whether to use the start or end of `rule`.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      " |                                                      freq='A',\n",
      " |                                                      periods=2))\n",
      " |      >>> s\n",
      " |      2012    1\n",
      " |      2013    2\n",
      " |      Freq: A-DEC, dtype: int64\n",
      " |      \n",
      " |      Resample by month using 'start' `convention`. Values are assigned to\n",
      " |      the first month of the period.\n",
      " |      \n",
      " |      >>> s.resample('M', convention='start').asfreq().head()\n",
      " |      2012-01    1.0\n",
      " |      2012-02    NaN\n",
      " |      2012-03    NaN\n",
      " |      2012-04    NaN\n",
      " |      2012-05    NaN\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      Resample by month using 'end' `convention`. Values are assigned to\n",
      " |      the last month of the period.\n",
      " |      \n",
      " |      >>> s.resample('M', convention='end').asfreq()\n",
      " |      2012-12    1.0\n",
      " |      2013-01    NaN\n",
      " |      2013-02    NaN\n",
      " |      2013-03    NaN\n",
      " |      2013-04    NaN\n",
      " |      2013-05    NaN\n",
      " |      2013-06    NaN\n",
      " |      2013-07    NaN\n",
      " |      2013-08    NaN\n",
      " |      2013-09    NaN\n",
      " |      2013-10    NaN\n",
      " |      2013-11    NaN\n",
      " |      2013-12    2.0\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      For DataFrame objects, the keyword ``on`` can be used to specify the\n",
      " |      column instead of the index for resampling.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(data=9*[range(4)], columns=['a', 'b', 'c', 'd'])\n",
      " |      >>> df['time'] = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> df.resample('3T', on='time').sum()\n",
      " |                           a  b  c  d\n",
      " |      time\n",
      " |      2000-01-01 00:00:00  0  3  6  9\n",
      " |      2000-01-01 00:03:00  0  3  6  9\n",
      " |      2000-01-01 00:06:00  0  3  6  9\n",
      " |      \n",
      " |      For a DataFrame with MultiIndex, the keyword ``level`` can be used to\n",
      " |      specify on level the resampling needs to take place.\n",
      " |      \n",
      " |      >>> time = pd.date_range('1/1/2000', periods=5, freq='T')\n",
      " |      >>> df2 = pd.DataFrame(data=10*[range(4)],\n",
      " |                             columns=['a', 'b', 'c', 'd'],\n",
      " |                             index=pd.MultiIndex.from_product([time, [1, 2]])\n",
      " |                             )\n",
      " |      >>> df2.resample('3T', level=0).sum()\n",
      " |                           a  b   c   d\n",
      " |      2000-01-01 00:00:00  0  6  12  18\n",
      " |      2000-01-01 00:03:00  0  4   8  12\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      groupby : Group by mapping, function, label, or list of labels.\n",
      " |  \n",
      " |  sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)\n",
      " |      Return a random sample of items from an axis of object.\n",
      " |      \n",
      " |      You can use `random_state` for reproducibility.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : boolean, optional\n",
      " |          Sample with or without replacement. Default = False.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          inf and -inf values not allowed.\n",
      " |      random_state : int or numpy.random.RandomState, optional\n",
      " |          Seed for the random number generator (if int), or numpy RandomState\n",
      " |          object.\n",
      " |      axis : int or string, optional\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type (0 for Series and DataFrames, 1 for Panels).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A new object of same type as caller.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Generate an example ``Series`` and ``DataFrame``:\n",
      " |      \n",
      " |      >>> s = pd.Series(np.random.randn(50))\n",
      " |      >>> s.head()\n",
      " |      0   -0.038497\n",
      " |      1    1.820773\n",
      " |      2   -0.972766\n",
      " |      3   -1.598270\n",
      " |      4   -1.095526\n",
      " |      dtype: float64\n",
      " |      >>> df = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n",
      " |      >>> df.head()\n",
      " |                A         B         C         D\n",
      " |      0  0.016443 -2.318952 -0.566372 -1.028078\n",
      " |      1 -1.051921  0.438836  0.658280 -0.175797\n",
      " |      2 -1.243569 -0.364626 -0.215065  0.057736\n",
      " |      3  1.768216  0.404512 -0.385604 -1.457834\n",
      " |      4  1.072446 -1.137172  0.314194 -0.046661\n",
      " |      \n",
      " |      Next extract a random sample from both of these objects...\n",
      " |      \n",
      " |      3 random elements from the ``Series``:\n",
      " |      \n",
      " |      >>> s.sample(n=3)\n",
      " |      27   -0.994689\n",
      " |      55   -1.049016\n",
      " |      67   -0.224565\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      And a random 10% of the ``DataFrame`` with replacement:\n",
      " |      \n",
      " |      >>> df.sample(frac=0.1, replace=True)\n",
      " |                 A         B         C         D\n",
      " |      35  1.981780  0.142106  1.817165 -0.290805\n",
      " |      49 -1.336199 -0.448634 -0.789640  0.217116\n",
      " |      40  0.823173 -0.078816  1.009536  1.015108\n",
      " |      15  1.421154 -0.055301 -1.922594 -0.019696\n",
      " |      6  -0.148339  0.832938  1.787600 -1.383767\n",
      " |      \n",
      " |      You can use `random state` for reproducibility:\n",
      " |      \n",
      " |      >>> df.sample(random_state=1)\n",
      " |      A         B         C         D\n",
      " |      37 -2.027662  0.103611  0.237496 -0.165867\n",
      " |      43 -0.259323 -0.583426  1.516140 -0.479118\n",
      " |      12 -1.686325 -0.579510  0.985195 -0.460286\n",
      " |      8   1.167946  0.429082  1.215742 -1.636041\n",
      " |      9   1.197475 -0.864188  1.554031 -1.505264\n",
      " |  \n",
      " |  select(self, crit, axis=0)\n",
      " |      Return data corresponding to axis labels matching criteria\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use df.loc[df.index.map(crit)] to select via labels\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      crit : function\n",
      " |          To be called on each index (label). Should return True or False\n",
      " |      axis : int\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      selection : type of caller\n",
      " |  \n",
      " |  set_axis(self, labels, axis=0, inplace=None)\n",
      " |      Assign desired index to given axis.\n",
      " |      \n",
      " |      Indexes for column or row labels can be changed by assigning\n",
      " |      a list-like or Index.\n",
      " |      \n",
      " |      .. versionchanged:: 0.21.0\n",
      " |      \n",
      " |         The signature is now `labels` and `axis`, consistent with\n",
      " |         the rest of pandas API. Previously, the `axis` and `labels`\n",
      " |         arguments were respectively the first and second positional\n",
      " |         arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : list-like, Index\n",
      " |          The values for the new index.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to update. The value 0 identifies the rows, and 1\n",
      " |          identifies the columns.\n",
      " |      \n",
      " |      inplace : boolean, default None\n",
      " |          Whether to return a new %(klass)s instance.\n",
      " |      \n",
      " |          .. warning::\n",
      " |      \n",
      " |             ``inplace=None`` currently falls back to to True, but in a\n",
      " |             future version, will default to False. Use inplace=True\n",
      " |             explicitly rather than relying on the default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : %(klass)s or None\n",
      " |          An object of same type as caller if inplace=False, None otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.rename_axis : Alter the name of the index or columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.set_axis(['a', 'b', 'c'], axis=0, inplace=False)\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      c    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The original object is not modified.\n",
      " |      \n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      \n",
      " |      Change the row labels.\n",
      " |      \n",
      " |      >>> df.set_axis(['a', 'b', 'c'], axis='index', inplace=False)\n",
      " |         A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      \n",
      " |      Change the column labels.\n",
      " |      \n",
      " |      >>> df.set_axis(['I', 'II'], axis='columns', inplace=False)\n",
      " |         I  II\n",
      " |      0  1   4\n",
      " |      1  2   5\n",
      " |      2  3   6\n",
      " |      \n",
      " |      Now, update the labels inplace.\n",
      " |      \n",
      " |      >>> df.set_axis(['i', 'ii'], axis='columns', inplace=True)\n",
      " |      >>> df\n",
      " |         i  ii\n",
      " |      0  1   4\n",
      " |      1  2   5\n",
      " |      2  3   6\n",
      " |  \n",
      " |  slice_shift(self, periods=1, axis=0)\n",
      " |      Equivalent to `shift` without copying data. The shifted data will\n",
      " |      not include the dropped periods and the shifted axis will be smaller\n",
      " |      than the original.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      " |      later during alignment.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : same type as caller\n",
      " |  \n",
      " |  squeeze(self, axis=None)\n",
      " |      Squeeze length 1 dimensions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : None, integer or string axis name, optional\n",
      " |          The axis to squeeze if 1-sized.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar if 1-sized, else original object\n",
      " |  \n",
      " |  swapaxes(self, axis1, axis2, copy=True)\n",
      " |      Interchange axes and swap values axes appropriately\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : same as input\n",
      " |  \n",
      " |  tail(self, n=5)\n",
      " |      Return the last `n` rows.\n",
      " |      \n",
      " |      This function returns last `n` rows from the object based on\n",
      " |      position. It is useful for quickly verifying data, for example,\n",
      " |      after sorting or appending rows.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The last `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.head : The first `n` rows of the caller object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal':['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the last 5 lines\n",
      " |      \n",
      " |      >>> df.tail()\n",
      " |         animal\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |      \n",
      " |      Viewing the last `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.tail(3)\n",
      " |        animal\n",
      " |      6  shark\n",
      " |      7  whale\n",
      " |      8  zebra\n",
      " |  \n",
      " |  take(self, indices, axis=0, convert=None, is_copy=True, **kwargs)\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      convert : bool, default True\n",
      " |          Whether to convert negative indices into positive ones.\n",
      " |          For example, ``-1`` would map to the ``len(axis) - 1``.\n",
      " |          The conversions are similar to the behavior of indexing a\n",
      " |          regular Python list.\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |             In the future, negative indices will always be converted.\n",
      " |      \n",
      " |      is_copy : bool, default True\n",
      " |          Whether to return a copy of the original object or not.\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : type of caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      " |      ...                    ('parrot', 'bird',     24.0),\n",
      " |      ...                    ('lion',   'mammal',   80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                    columns=['name', 'class', 'max_speed'],\n",
      " |      ...                    index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  to_clipboard(self, excel=True, sep=None, **kwargs)\n",
      " |      Copy object to the system clipboard.\n",
      " |      \n",
      " |      Write a text representation of object to the system clipboard.\n",
      " |      This can be pasted into Excel, for example.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : bool, default True\n",
      " |          - True, use the provided separator, writing in a csv format for\n",
      " |            allowing easy pasting into excel.\n",
      " |          - False, write a string representation of the object to the\n",
      " |            clipboard.\n",
      " |      \n",
      " |      sep : str, default ``'\\t'``\n",
      " |          Field delimiter.\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to DataFrame.to_csv.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_csv : Write a DataFrame to a comma-separated values\n",
      " |          (csv) file.\n",
      " |      read_clipboard : Read text from clipboard and pass to read_table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform.\n",
      " |      \n",
      " |        - Linux : `xclip`, or `xsel` (with `gtk` or `PyQt4` modules)\n",
      " |        - Windows : none\n",
      " |        - OS X : none\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Copy the contents of a DataFrame to the clipboard.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])\n",
      " |      >>> df.to_clipboard(sep=',')\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # ,A,B,C\n",
      " |      ... # 0,1,2,3\n",
      " |      ... # 1,4,5,6\n",
      " |      \n",
      " |      We can omit the the index by passing the keyword `index` and setting\n",
      " |      it to false.\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',', index=False)\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # A,B,C\n",
      " |      ... # 1,2,3\n",
      " |      ... # 4,5,6\n",
      " |  \n",
      " |  to_dense(self)\n",
      " |      Return dense representation of NDFrame (as opposed to sparse)\n",
      " |  \n",
      " |  to_hdf(self, path_or_buf, key, **kwargs)\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |      \n",
      " |      Hierarchical Data Format (HDF) is self-describing, allowing an\n",
      " |      application to interpret the structure and contents of a file with\n",
      " |      no outside information. One HDF file can hold a mix of related objects\n",
      " |      which can be accessed as a group or as individual objects.\n",
      " |      \n",
      " |      In order to add another DataFrame or Series to an existing HDF file\n",
      " |      please use append mode and a different a key.\n",
      " |      \n",
      " |      For more information see the :ref:`user guide <io.hdf5>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or pandas.HDFStore\n",
      " |          File path or HDFStore object.\n",
      " |      key : str\n",
      " |          Identifier for the group in the store.\n",
      " |      mode : {'a', 'w', 'r+'}, default 'a'\n",
      " |          Mode to open file:\n",
      " |      \n",
      " |          - 'w': write, a new file is created (an existing file with\n",
      " |            the same name would be deleted).\n",
      " |          - 'a': append, an existing file is opened for reading and\n",
      " |            writing, and if the file does not exist it is created.\n",
      " |          - 'r+': similar to 'a', but the file must already exist.\n",
      " |      format : {'fixed', 'table'}, default 'fixed'\n",
      " |          Possible values:\n",
      " |      \n",
      " |          - 'fixed': Fixed format. Fast writing/reading. Not-appendable,\n",
      " |            nor searchable.\n",
      " |          - 'table': Table format. Write as a PyTables Table structure\n",
      " |            which may perform worse but allow more flexible operations\n",
      " |            like searching / selecting subsets of the data.\n",
      " |      append : bool, default False\n",
      " |          For Table formats, append the input data to the existing.\n",
      " |      data_columns :  list of columns or True, optional\n",
      " |          List of columns to create as indexed data columns for on-disk\n",
      " |          queries, or True to use all columns. By default only the axes\n",
      " |          of the object are indexed. See :ref:`io.hdf5-query-data-columns`.\n",
      " |          Applicable only to format='table'.\n",
      " |      complevel : {0-9}, optional\n",
      " |          Specifies a compression level for data.\n",
      " |          A value of 0 disables compression.\n",
      " |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      " |          Specifies the compression library to be used.\n",
      " |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      " |          (default if no compressor specified: 'blosc:blosclz'):\n",
      " |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      " |          'blosc:zlib', 'blosc:zstd'}.\n",
      " |          Specifying a compression library which is not available issues\n",
      " |          a ValueError.\n",
      " |      fletcher32 : bool, default False\n",
      " |          If applying compression use the fletcher32 checksum.\n",
      " |      dropna : bool, default False\n",
      " |          If true, ALL nan rows will not be written to store.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.read_hdf : Read from HDF file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_feather : Write out feather-format for DataFrames.\n",
      " |      DataFrame.to_csv : Write out to a csv file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
      " |      ...                   index=['a', 'b', 'c'])\n",
      " |      >>> df.to_hdf('data.h5', key='df', mode='w')\n",
      " |      \n",
      " |      We can add another object to the same file:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.to_hdf('data.h5', key='s')\n",
      " |      \n",
      " |      Reading from HDF file:\n",
      " |      \n",
      " |      >>> pd.read_hdf('data.h5', 'df')\n",
      " |      A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      >>> pd.read_hdf('data.h5', 's')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Deleting file with data:\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove('data.h5')\n",
      " |  \n",
      " |  to_json(self, path_or_buf=None, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression=None, index=True)\n",
      " |      Convert the object to a JSON string.\n",
      " |      \n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : string or file handle, optional\n",
      " |          File path or object. If not specified, the result is returned as\n",
      " |          a string.\n",
      " |      orient : string\n",
      " |          Indication of expected JSON string format.\n",
      " |      \n",
      " |          * Series\n",
      " |      \n",
      " |            - default is 'index'\n",
      " |            - allowed values are: {'split','records','index'}\n",
      " |      \n",
      " |          * DataFrame\n",
      " |      \n",
      " |            - default is 'columns'\n",
      " |            - allowed values are:\n",
      " |              {'split','records','index','columns','values'}\n",
      " |      \n",
      " |          * The format of the JSON string\n",
      " |      \n",
      " |            - 'split' : dict like {'index' -> [index],\n",
      " |              'columns' -> [columns], 'data' -> [values]}\n",
      " |            - 'records' : list like\n",
      " |              [{column -> value}, ... , {column -> value}]\n",
      " |            - 'index' : dict like {index -> {column -> value}}\n",
      " |            - 'columns' : dict like {column -> {index -> value}}\n",
      " |            - 'values' : just the values array\n",
      " |            - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      " |              describing the data, and the data component is\n",
      " |              like ``orient='records'``.\n",
      " |      \n",
      " |              .. versionchanged:: 0.20.0\n",
      " |      \n",
      " |      date_format : {None, 'epoch', 'iso'}\n",
      " |          Type of date conversion. 'epoch' = epoch milliseconds,\n",
      " |          'iso' = ISO8601. The default depends on the `orient`. For\n",
      " |          ``orient='table'``, the default is 'iso'. For all other orients,\n",
      " |          the default is 'epoch'.\n",
      " |      double_precision : int, default 10\n",
      " |          The number of decimal places to use when encoding\n",
      " |          floating point values.\n",
      " |      force_ascii : boolean, default True\n",
      " |          Force encoded string to be ASCII.\n",
      " |      date_unit : string, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      lines : boolean, default False\n",
      " |          If 'orient' is 'records' write out line delimited json format. Will\n",
      " |          throw ValueError if incorrect 'orient' since others are not list\n",
      " |          like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      compression : {None, 'gzip', 'bz2', 'zip', 'xz'}\n",
      " |          A string representing the compression to use in the output file,\n",
      " |          only used when the first argument is a filename.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      index : boolean, default True\n",
      " |          Whether to include the index values in the JSON string. Not\n",
      " |          including the index (``index=False``) is only supported when\n",
      " |          orient is 'split' or 'table'.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.read_json\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                   index=['row 1', 'row 2'],\n",
      " |      ...                   columns=['col 1', 'col 2'])\n",
      " |      >>> df.to_json(orient='split')\n",
      " |      '{\"columns\":[\"col 1\",\"col 2\"],\n",
      " |        \"index\":[\"row 1\",\"row 2\"],\n",
      " |        \"data\":[[\"a\",\"b\"],[\"c\",\"d\"]]}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      " |      Note that index labels are not preserved with this encoding.\n",
      " |      \n",
      " |      >>> df.to_json(orient='records')\n",
      " |      '[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='index')\n",
      " |      '{\"row 1\":{\"col 1\":\"a\",\"col 2\":\"b\"},\"row 2\":{\"col 1\":\"c\",\"col 2\":\"d\"}}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='columns')\n",
      " |      '{\"col 1\":{\"row 1\":\"a\",\"row 2\":\"c\"},\"col 2\":{\"row 1\":\"b\",\"row 2\":\"d\"}}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='values')\n",
      " |      '[[\"a\",\"b\"],[\"c\",\"d\"]]'\n",
      " |      \n",
      " |      Encoding with Table Schema\n",
      " |      \n",
      " |      >>> df.to_json(orient='table')\n",
      " |      '{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"string\"},\n",
      " |                              {\"name\": \"col 1\", \"type\": \"string\"},\n",
      " |                              {\"name\": \"col 2\", \"type\": \"string\"}],\n",
      " |                   \"primaryKey\": \"index\",\n",
      " |                   \"pandas_version\": \"0.20.0\"},\n",
      " |        \"data\": [{\"index\": \"row 1\", \"col 1\": \"a\", \"col 2\": \"b\"},\n",
      " |                 {\"index\": \"row 2\", \"col 1\": \"c\", \"col 2\": \"d\"}]}'\n",
      " |  \n",
      " |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None)\n",
      " |      Render an object to a tabular environment table. You can splice\n",
      " |      this into a LaTeX document. Requires \\\\usepackage{booktabs}.\n",
      " |      \n",
      " |      .. versionchanged:: 0.20.2\n",
      " |         Added to Series\n",
      " |      \n",
      " |      `to_latex`-specific options:\n",
      " |      \n",
      " |      bold_rows : boolean, default False\n",
      " |          Make the row labels bold in the output\n",
      " |      column_format : str, default None\n",
      " |          The columns format as specified in `LaTeX table format\n",
      " |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g 'rcl' for 3\n",
      " |          columns\n",
      " |      longtable : boolean, default will be read from the pandas config module\n",
      " |          Default: False.\n",
      " |          Use a longtable environment instead of tabular. Requires adding\n",
      " |          a \\\\usepackage{longtable} to your LaTeX preamble.\n",
      " |      escape : boolean, default will be read from the pandas config module\n",
      " |          Default: True.\n",
      " |          When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |      encoding : str, default None\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      " |      decimal : string, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      multicolumn : boolean, default True\n",
      " |          Use \\multicolumn to enhance MultiIndex columns.\n",
      " |          The default will be read from the config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      multicolumn_format : str, default 'l'\n",
      " |          The alignment for multicolumns, similar to `column_format`\n",
      " |          The default will be read from the config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      multirow : boolean, default False\n",
      " |          Use \\multirow to enhance MultiIndex rows.\n",
      " |          Requires adding a \\\\usepackage{multirow} to your LaTeX preamble.\n",
      " |          Will print centered labels (instead of top-aligned)\n",
      " |          across the contained rows, separating groups via clines.\n",
      " |          The default will be read from the pandas config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |  \n",
      " |  to_msgpack(self, path_or_buf=None, encoding='utf-8', **kwargs)\n",
      " |      msgpack (serialize) object to input file path\n",
      " |      \n",
      " |      THIS IS AN EXPERIMENTAL LIBRARY and the storage format\n",
      " |      may not be stable until a future release.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string File path, buffer-like, or None\n",
      " |          if None, return generated string\n",
      " |      append : boolean whether to append to an existing msgpack\n",
      " |          (default is False)\n",
      " |      compress : type of compressor (zlib or blosc), default to None (no\n",
      " |          compression)\n",
      " |  \n",
      " |  to_pickle(self, path, compression='infer', protocol=4)\n",
      " |      Pickle (serialize) object to file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str\n",
      " |          File path where the pickled object will be stored.\n",
      " |      compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None},         default 'infer'\n",
      " |          A string representing the compression to use in the output file. By\n",
      " |          default, infers from the file extension in specified path.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      protocol : int\n",
      " |          Int which indicates which protocol should be used by the pickler,\n",
      " |          default HIGHEST_PROTOCOL (see [1]_ paragraph 12.1.2). The possible\n",
      " |          values for this parameter depend on the version of Python. For\n",
      " |          Python 2.x, possible values are 0, 1, 2. For Python>=3.0, 3 is a\n",
      " |          valid value. For Python >= 3.4, 4 is a valid value. A negative\n",
      " |          value for the protocol parameter is equivalent to setting its value\n",
      " |          to HIGHEST_PROTOCOL.\n",
      " |      \n",
      " |          .. [1] https://docs.python.org/3/library/pickle.html\n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_pickle : Load pickled pandas object (or any object) from file.\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_sql : Write DataFrame to a SQL database.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> original_df = pd.DataFrame({\"foo\": range(5), \"bar\": range(5, 10)})\n",
      " |      >>> original_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      >>> original_df.to_pickle(\"./dummy.pkl\")\n",
      " |      \n",
      " |      >>> unpickled_df = pd.read_pickle(\"./dummy.pkl\")\n",
      " |      >>> unpickled_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove(\"./dummy.pkl\")\n",
      " |  \n",
      " |  to_sql(self, name, con, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None)\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |      \n",
      " |      Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      " |      newly created, appended to, or overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : string\n",
      " |          Name of SQL table.\n",
      " |      con : sqlalchemy.engine.Engine or sqlite3.Connection\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library. Legacy support is provided for sqlite3.Connection objects.\n",
      " |      schema : string, optional\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          How to behave if the table already exists.\n",
      " |      \n",
      " |          * fail: Raise a ValueError.\n",
      " |          * replace: Drop the table before inserting new values.\n",
      " |          * append: Insert new values to the existing table.\n",
      " |      \n",
      " |      index : boolean, default True\n",
      " |          Write DataFrame index as a column. Uses `index_label` as the column\n",
      " |          name in the table.\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, optional\n",
      " |          Rows will be written in batches of this size at a time. By default,\n",
      " |          all rows will be written at once.\n",
      " |      dtype : dict, optional\n",
      " |          Specifying the datatype for columns. The keys should be the column\n",
      " |          names and the values should be the SQLAlchemy types or strings for\n",
      " |          the sqlite3 legacy mode.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the table already exists and `if_exists` is 'fail' (the\n",
      " |          default).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.read_sql : read a DataFrame from a table\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] http://docs.sqlalchemy.org\n",
      " |      .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create an in-memory SQLite database.\n",
      " |      \n",
      " |      >>> from sqlalchemy import create_engine\n",
      " |      >>> engine = create_engine('sqlite://', echo=False)\n",
      " |      \n",
      " |      Create a table from scratch with 3 rows.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      " |      >>> df\n",
      " |           name\n",
      " |      0  User 1\n",
      " |      1  User 2\n",
      " |      2  User 3\n",
      " |      \n",
      " |      >>> df.to_sql('users', con=engine)\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      " |      >>> df1.to_sql('users', con=engine, if_exists='append')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      " |       (0, 'User 4'), (1, 'User 5')]\n",
      " |      \n",
      " |      Overwrite the table with just ``df1``.\n",
      " |      \n",
      " |      >>> df1.to_sql('users', con=engine, if_exists='replace',\n",
      " |      ...            index_label='id')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 4'), (1, 'User 5')]\n",
      " |      \n",
      " |      Specify the dtype (especially useful for integers with missing values).\n",
      " |      Notice that while pandas is forced to store the data as floating point,\n",
      " |      the database supports nullable integers. When fetching the data with\n",
      " |      Python, we get back integer scalars.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      " |      >>> df\n",
      " |           A\n",
      " |      0  1.0\n",
      " |      1  NaN\n",
      " |      2  2.0\n",
      " |      \n",
      " |      >>> from sqlalchemy.types import Integer\n",
      " |      >>> df.to_sql('integers', con=engine, index=False,\n",
      " |      ...           dtype={\"A\": Integer()})\n",
      " |      \n",
      " |      >>> engine.execute(\"SELECT * FROM integers\").fetchall()\n",
      " |      [(1,), (None,), (2,)]\n",
      " |  \n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the pandas object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a DataArray for a Series\n",
      " |      a Dataset for a DataFrame\n",
      " |      a DataArray for higher dims\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      " |                             'B' : ['foo', 'bar', 'foo'],\n",
      " |                             'C' : np.arange(4.,7)})\n",
      " |      >>> df\n",
      " |         A    B    C\n",
      " |      0  1  foo  4.0\n",
      " |      1  1  bar  5.0\n",
      " |      2  2  foo  6.0\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (index: 3)\n",
      " |      Coordinates:\n",
      " |        * index    (index) int64 0 1 2\n",
      " |      Data variables:\n",
      " |          A        (index) int64 1 1 2\n",
      " |          B        (index) object 'foo' 'bar' 'foo'\n",
      " |          C        (index) float64 4.0 5.0 6.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      " |                             'B' : ['foo', 'bar', 'foo'],\n",
      " |                             'C' : np.arange(4.,7)}\n",
      " |                           ).set_index(['B','A'])\n",
      " |      >>> df\n",
      " |               C\n",
      " |      B   A\n",
      " |      foo 1  4.0\n",
      " |      bar 1  5.0\n",
      " |      foo 2  6.0\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (A: 2, B: 2)\n",
      " |      Coordinates:\n",
      " |        * B        (B) object 'bar' 'foo'\n",
      " |        * A        (A) int64 1 2\n",
      " |      Data variables:\n",
      " |          C        (B, A) float64 5.0 nan 4.0 6.0\n",
      " |      \n",
      " |      >>> p = pd.Panel(np.arange(24).reshape(4,3,2),\n",
      " |                       items=list('ABCD'),\n",
      " |                       major_axis=pd.date_range('20130101', periods=3),\n",
      " |                       minor_axis=['first', 'second'])\n",
      " |      >>> p\n",
      " |      <class 'pandas.core.panel.Panel'>\n",
      " |      Dimensions: 4 (items) x 3 (major_axis) x 2 (minor_axis)\n",
      " |      Items axis: A to D\n",
      " |      Major_axis axis: 2013-01-01 00:00:00 to 2013-01-03 00:00:00\n",
      " |      Minor_axis axis: first to second\n",
      " |      \n",
      " |      >>> p.to_xarray()\n",
      " |      <xarray.DataArray (items: 4, major_axis: 3, minor_axis: 2)>\n",
      " |      array([[[ 0,  1],\n",
      " |              [ 2,  3],\n",
      " |              [ 4,  5]],\n",
      " |             [[ 6,  7],\n",
      " |              [ 8,  9],\n",
      " |              [10, 11]],\n",
      " |             [[12, 13],\n",
      " |              [14, 15],\n",
      " |              [16, 17]],\n",
      " |             [[18, 19],\n",
      " |              [20, 21],\n",
      " |              [22, 23]]])\n",
      " |      Coordinates:\n",
      " |        * items       (items) object 'A' 'B' 'C' 'D'\n",
      " |        * major_axis  (major_axis) datetime64[ns] 2013-01-01 2013-01-02 2013-01-03  # noqa\n",
      " |        * minor_axis  (minor_axis) object 'first' 'second'\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `xarray docs <http://xarray.pydata.org/en/stable/>`__\n",
      " |  \n",
      " |  truncate(self, before=None, after=None, axis=None, copy=True)\n",
      " |      Truncate a Series or DataFrame before and after some index value.\n",
      " |      \n",
      " |      This is a useful shorthand for boolean indexing based on index\n",
      " |      values above or below certain thresholds.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date, string, int\n",
      " |          Truncate all rows before this index value.\n",
      " |      after : date, string, int\n",
      " |          Truncate all rows after this index value.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, optional\n",
      " |          Axis to truncate. Truncates the index (rows) by default.\n",
      " |      copy : boolean, default is True,\n",
      " |          Return a copy of the truncated section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The truncated Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by label.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the index being truncated contains only datetime values,\n",
      " |      `before` and `after` may be specified as strings instead of\n",
      " |      Timestamps.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      " |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      " |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      " |      ...                    index=[1, 2, 3, 4, 5])\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      1  a  f  k\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      5  e  j  o\n",
      " |      \n",
      " |      >>> df.truncate(before=2, after=4)\n",
      " |         A  B  C\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      \n",
      " |      The columns of a DataFrame can be truncated.\n",
      " |      \n",
      " |      >>> df.truncate(before=\"A\", after=\"B\", axis=\"columns\")\n",
      " |         A  B\n",
      " |      1  a  f\n",
      " |      2  b  g\n",
      " |      3  c  h\n",
      " |      4  d  i\n",
      " |      5  e  j\n",
      " |      \n",
      " |      For Series, only rows can be truncated.\n",
      " |      \n",
      " |      >>> df['A'].truncate(before=2, after=4)\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    d\n",
      " |      Name: A, dtype: object\n",
      " |      \n",
      " |      The index values in ``truncate`` can be datetimes or string\n",
      " |      dates.\n",
      " |      \n",
      " |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      " |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      " |      >>> df.tail()\n",
      " |                           A\n",
      " |      2016-01-31 23:59:56  1\n",
      " |      2016-01-31 23:59:57  1\n",
      " |      2016-01-31 23:59:58  1\n",
      " |      2016-01-31 23:59:59  1\n",
      " |      2016-02-01 00:00:00  1\n",
      " |      \n",
      " |      >>> df.truncate(before=pd.Timestamp('2016-01-05'),\n",
      " |      ...             after=pd.Timestamp('2016-01-10')).tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Because the index is a DatetimeIndex containing only dates, we can\n",
      " |      specify `before` and `after` as strings. They will be coerced to\n",
      " |      Timestamps before truncation.\n",
      " |      \n",
      " |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Note that ``truncate`` assumes a 0 value for any unspecified time\n",
      " |      component (midnight). This differs from partial string slicing, which\n",
      " |      returns any partially matching dates.\n",
      " |      \n",
      " |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      " |                           A\n",
      " |      2016-01-10 23:59:55  1\n",
      " |      2016-01-10 23:59:56  1\n",
      " |      2016-01-10 23:59:57  1\n",
      " |      2016-01-10 23:59:58  1\n",
      " |      2016-01-10 23:59:59  1\n",
      " |  \n",
      " |  tshift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, default None\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      " |      axis : int or basestring\n",
      " |          Corresponds to the axis that contains the Index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : NDFrame\n",
      " |  \n",
      " |  tz_convert(self, tz, axis=0, level=None, copy=True)\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |  \n",
      " |  tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous='raise')\n",
      " |      Localize tz-naive TimeSeries to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |  \n",
      " |  where(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where `cond` is True and otherwise are from\n",
      " |      `other`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame, array-like, or callable\n",
      " |          Where `cond` is True, keep the original value. Where\n",
      " |          False, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the NDFrame and\n",
      " |          should return boolean NDFrame or array. The callable must\n",
      " |          not change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as cond.\n",
      " |      \n",
      " |      other : scalar, NDFrame, or callable\n",
      " |          Entries where `cond` is False are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the NDFrame and\n",
      " |          should return scalar or NDFrame. The callable must not\n",
      " |          change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as other.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The where method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``where`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10.0\n",
      " |      1    10.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.mask`\n",
      " |  \n",
      " |  xs(self, key, axis=0, level=None, drop_level=True)\n",
      " |      Returns a cross-section (row(s) or column(s)) from the\n",
      " |      Series/DataFrame. Defaults to cross-section on the rows (axis=0).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |          Some label contained in the index, or partially in a MultiIndex\n",
      " |      axis : int, default 0\n",
      " |          Axis to retrieve cross-section on\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      drop_level : boolean, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      a  4  5  2\n",
      " |      b  4  0  9\n",
      " |      c  9  7  3\n",
      " |      >>> df.xs('a')\n",
      " |      A    4\n",
      " |      B    5\n",
      " |      C    2\n",
      " |      Name: a\n",
      " |      >>> df.xs('C', axis=1)\n",
      " |      a    2\n",
      " |      b    9\n",
      " |      c    3\n",
      " |      Name: C\n",
      " |      \n",
      " |      >>> df\n",
      " |                          A  B  C  D\n",
      " |      first second third\n",
      " |      bar   one    1      4  1  8  9\n",
      " |            two    1      7  5  5  0\n",
      " |      baz   one    1      6  6  8  0\n",
      " |            three  2      5  3  5  3\n",
      " |      >>> df.xs(('baz', 'three'))\n",
      " |             A  B  C  D\n",
      " |      third\n",
      " |      2      5  3  5  3\n",
      " |      >>> df.xs('one', level=1)\n",
      " |                   A  B  C  D\n",
      " |      first third\n",
      " |      bar   1      4  1  8  9\n",
      " |      baz   1      6  6  8  0\n",
      " |      >>> df.xs(('baz', 2), level=[0, 'third'])\n",
      " |              A  B  C  D\n",
      " |      second\n",
      " |      three   5  3  5  3\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      xs : Series or DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      xs is only for getting, not setting values.\n",
      " |      \n",
      " |      MultiIndex Slicers is a generic way to get/set values on any level or\n",
      " |      levels.  It is a superset of xs functionality, see\n",
      " |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  at\n",
      " |      Access a single value for a row/column label pair.\n",
      " |      \n",
      " |      Similar to ``loc``, in that both provide label-based lookups. Use\n",
      " |      ``at`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Access a single value for a row/column pair by integer\n",
      " |          position\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s)\n",
      " |      Series.at : Access a single value using a label\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      4   0   2   3\n",
      " |      5   0   4   1\n",
      " |      6  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B']\n",
      " |      2\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B'] = 10\n",
      " |      >>> df.at[4, 'B']\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a Series\n",
      " |      \n",
      " |      >>> df.loc[5].at['B']\n",
      " |      4\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          When label does not exist in DataFrame\n",
      " |  \n",
      " |  blocks\n",
      " |      Internal property, property synonym for as_blocks()\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |  \n",
      " |  iat\n",
      " |      Access a single value for a row/column pair by integer position.\n",
      " |      \n",
      " |      Similar to ``iloc``, in that both provide integer-based lookups. Use\n",
      " |      ``iat`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s)\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer position(s)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      0   0   2   3\n",
      " |      1   0   4   1\n",
      " |      2  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2]\n",
      " |      1\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2] = 10\n",
      " |      >>> df.iat[1, 2]\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a series\n",
      " |      \n",
      " |      >>> df.loc[0].iat[1]\n",
      " |      2\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          When integer position is out of bounds\n",
      " |  \n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |      \n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |        or Panel) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |      \n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`\n",
      " |  \n",
      " |  is_copy\n",
      " |  \n",
      " |  ix\n",
      " |      A primarily label-location based indexer, with integer position\n",
      " |      fallback.\n",
      " |      \n",
      " |      Warning: Starting in 0.20.0, the .ix indexer is deprecated, in\n",
      " |      favor of the more strict .iloc and .loc indexers.\n",
      " |      \n",
      " |      ``.ix[]`` supports mixed integer and label based access. It is\n",
      " |      primarily label based, but will fall back to integer positional\n",
      " |      access unless the corresponding axis is of integer type.\n",
      " |      \n",
      " |      ``.ix`` is the most general indexer and will support any of the\n",
      " |      inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n",
      " |      point label schemes. ``.ix`` is exceptionally useful when dealing\n",
      " |      with mixed positional and label based hierarchical indexes.\n",
      " |      \n",
      " |      However, when an axis is integer based, ONLY label based access\n",
      " |      and not positional access is supported. Thus, in such cases, it's\n",
      " |      usually better to be explicit and use ``.iloc`` or ``.loc``.\n",
      " |      \n",
      " |      See more at :ref:`Advanced Indexing <advanced>`.\n",
      " |  \n",
      " |  loc\n",
      " |      Access a group of rows and columns by label(s) or a boolean array.\n",
      " |      \n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'``.\n",
      " |      \n",
      " |        .. warning:: Note that contrary to usual python slices, **both** the\n",
      " |            start and the stop are included\n",
      " |      \n",
      " |      - A boolean array of the same length as the axis being sliced,\n",
      " |        e.g. ``[True, False, True]``.\n",
      " |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |        or Panel) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      See more at :ref:`Selection by Label <indexing.label>`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair\n",
      " |      DataFrame.iloc : Access group of rows and columns by integer position(s)\n",
      " |      DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n",
      " |          Series/DataFrame.\n",
      " |      Series.loc : Access group of values using labels\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Getting values**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=['cobra', 'viper', 'sidewinder'],\n",
      " |      ...      columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label. Note this returns the row as a Series.\n",
      " |      \n",
      " |      >>> df.loc['viper']\n",
      " |      max_speed    4\n",
      " |      shield       5\n",
      " |      Name: viper, dtype: int64\n",
      " |      \n",
      " |      List of labels. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder']]\n",
      " |                  max_speed  shield\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label for row and column\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice with labels for row and single label for column. As mentioned\n",
      " |      above, note that both the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc['cobra':'viper', 'max_speed']\n",
      " |      cobra    1\n",
      " |      viper    4\n",
      " |      Name: max_speed, dtype: int64\n",
      " |      \n",
      " |      Boolean list with the same length as the row axis\n",
      " |      \n",
      " |      >>> df.loc[[False, False, True]]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series with column labels specified\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6, ['max_speed']]\n",
      " |                  max_speed\n",
      " |      sidewinder          7\n",
      " |      \n",
      " |      Callable that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[lambda df: df['shield'] == 8]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      **Setting values**\n",
      " |      \n",
      " |      Set value for all items matching the list of labels\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire row\n",
      " |      \n",
      " |      >>> df.loc['cobra'] = 10\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              10      10\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire column\n",
      " |      \n",
      " |      >>> df.loc[:, 'max_speed'] = 30\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper              30      50\n",
      " |      sidewinder         30      50\n",
      " |      \n",
      " |      Set value for rows matching callable condition\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 35] = 0\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper               0       0\n",
      " |      sidewinder          0       0\n",
      " |      \n",
      " |      **Getting values on a DataFrame with an index that has integer labels**\n",
      " |      \n",
      " |      Another example using integers for the index\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      Slice with integer labels for rows. As mentioned above, note that both\n",
      " |      the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc[7:9]\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      **Getting values with a MultiIndex**\n",
      " |      \n",
      " |      A number of examples using a DataFrame with a MultiIndex\n",
      " |      \n",
      " |      >>> tuples = [\n",
      " |      ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
      " |      ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
      " |      ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n",
      " |      ... ]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples)\n",
      " |      >>> values = [[12, 2], [0, 4], [10, 20],\n",
      " |      ...         [1, 4], [7, 1], [16, 36]]\n",
      " |      >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
      " |      >>> df\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Single label. Note this returns a DataFrame with a single index.\n",
      " |      \n",
      " |      >>> df.loc['cobra']\n",
      " |               max_speed  shield\n",
      " |      mark i          12       2\n",
      " |      mark ii          0       4\n",
      " |      \n",
      " |      Single index tuple. Note this returns a Series.\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark ii')]\n",
      " |      max_speed    0\n",
      " |      shield       4\n",
      " |      Name: (cobra, mark ii), dtype: int64\n",
      " |      \n",
      " |      Single label for row and column. Similar to passing in a tuple, this\n",
      " |      returns a Series.\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'mark i']\n",
      " |      max_speed    12\n",
      " |      shield        2\n",
      " |      Name: (cobra, mark i), dtype: int64\n",
      " |      \n",
      " |      Single tuple. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[[('cobra', 'mark ii')]]\n",
      " |                     max_speed  shield\n",
      " |      cobra mark ii          0       4\n",
      " |      \n",
      " |      Single tuple for the index with a single label for the column\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'), 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice from index tuple to single label\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):'viper']\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Slice from index tuple to index tuple\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n",
      " |                          max_speed  shield\n",
      " |      cobra      mark i          12       2\n",
      " |                 mark ii          0       4\n",
      " |      sidewinder mark i          10      20\n",
      " |                 mark ii          1       4\n",
      " |      viper      mark ii          7       1\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError:\n",
      " |          when any items are not found\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by bytes(obj) in py3 only.\n",
      " |      Yields a bytestring in both py2/py3.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string representation for a particular Object\n",
      " |      \n",
      " |      Invoked by str(df) in both py2/py3.\n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion\n",
      " |      Only provide 'public' methods\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TimeSeries())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
